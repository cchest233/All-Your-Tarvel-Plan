# 创建文本转语音请求
Source: https://docs.siliconflow.com/cn/api-reference/audio/create-speech

post /audio/speech
Generate audio from input text. The data generated by the interface is the binary data of the audio, which requires the user to handle it themselves. Reference:https://docs.siliconflow.com/capabilities/text-to-speech#5



# 删除参考音频
Source: https://docs.siliconflow.com/cn/api-reference/audio/delete-voice

post /audio/voice/deletions
Delete user-defined voice style



# 上传参考音频
Source: https://docs.siliconflow.com/cn/api-reference/audio/upload-voice

post /uploads/audio/voice
Upload user-provided voice style, which can be in base64 encoding or file format. Refer to (https://docs.siliconflow.com/capabilities/text-to-speech#2-2)



# 参考音频列表获取
Source: https://docs.siliconflow.com/cn/api-reference/audio/voice-list

get /audio/voice/list
Get list of user-defined voice styles



# 创建文本对话请求
Source: https://docs.siliconflow.com/cn/api-reference/chat-completions/chat-completions

post /chat/completions
Creates a model response for the given chat conversation.



# 创建图片生成请求
Source: https://docs.siliconflow.com/cn/api-reference/images/images-generations

post /images/generations
Creates an image response for the given prompt. The URL for the generated image is valid for one hour. Please make sure to download and store it promptly to avoid any issues due to URL expiration.



# 获取用户模型列表
Source: https://docs.siliconflow.com/cn/api-reference/models/get-model-list

get /models
Retrieve models information.



# 获取用户账户信息
Source: https://docs.siliconflow.com/cn/api-reference/userinfo/get-user-info

get /user/info
Get user information including balance and status



# 获取视频生成链接请求
Source: https://docs.siliconflow.com/cn/api-reference/videos/get_videos_status

post /video/status
Get the user-generated video. The URL for the generated video is valid for one hour. Please make sure to download and store it promptly to avoid any issues due to URL expiration.



# 创建视频生成请求
Source: https://docs.siliconflow.com/cn/api-reference/videos/videos_submit

post /video/submit
Generate a video through the input prompt. This API returns the user's current request ID. The user needs to poll the status interface to get the specific video link. The generated result is valid for 10 minutes, so please retrieve the video link promptly.



# 错误处理
Source: https://docs.siliconflow.com/cn/faqs/error-code



**1. 尝试获取 HTTP 错误代码，初步定位问题**

a. 在代码中，尽量把错误码和报错信息（message）打印出来，利用这些信息，可以定位大部分问题。

```shell
HTTP/1.1 400 Bad Request
Date: Thu, 19 Dec 2024 08:39:19 GMT
Content-Type: application/json; charset=utf-8
Content-Length: 87
Connection: keep-alive

{"code":20012,"message":"Model does not exist. Please check it carefully.","data":null}

```

* 常见错误代码及原因：
  * **400**：参数不正确，请参考报错信息（message）修正不合法的请求参数；
  * **401**：API Key 没有正确设置；
  * **403**：权限不够，最常见的原因是该模型需要实名认证，其他情况参考报错信息（message）；
  * **429**：触发了 rate limits；参考报错信息（message）判断触发的是 `RPM /RPD / TPM / TPD / IPM / IPD` 中的具体哪一种，可以参考 [Rate Limits](https://docs.siliconflow.com/rate-limits/rate-limit-and-upgradation) 了解具体的限流策略
  * **504 / 503**：
    * 一般是服务系统负载比较高，可以稍后尝试；
    * 对于对话和文本转语音请求，可以尝试使用流式输出（"stream" : true），参考 [流式输出](https://docs.siliconflow.com/faqs/stream-mode)；
  * **500**：服务发生了未知的错误，可以联系相关人员进行排查

b. 如果客户端没有输出相应的信息，可以考虑在命令行下运行 curl 命令（以 LLM 模型为例）:）:

```shell
curl --request POST \
   --url https://api.ap.siliconflow.com/v1/chat/completions \
   --header 'accept: application/json' \
   --header 'authorization: Bearer 改成你的 apikey' \
   --header 'content-type: application/json' \
   --data '
{
  "model": "记得改模型",
  "messages": [
    {
      "role": "user",
      "content": "你好"
    }
  ],
  "max_tokens": 128
}' -i
```

**2. 可以尝试换一个模型，看看问题是否依旧**

**3. 如果开了代理，可以考虑将代理关闭后再尝试访问**

<Note> 如遇其他问题，请发送邮件至 [help@siliconflow.com](mailto:help@siliconflow.com)。</Note>


# 模型问题
Source: https://docs.siliconflow.com/cn/faqs/misc



## 1. 模型输出乱码

目前看到部分模型在不设置参数的情况下，容易出现乱码，遇到上述情况，可以尝试设置`temperature`，`top_k`，`top_p`，`frequency_penalty`这些参数。

对应的 payload 修改为如下形式，不同语言酌情调整

```python
    payload = {
        "model": "Qwen/Qwen2.5-Math-72B-Instruct",
        "messages": [
            {
                "role": "user",
                "content": "1+1=?",
            }
        ],
        "max_tokens": 200,  # 按需添加
        "temperature": 0.7, # 按需添加
        "top_k": 50,        # 按需添加
        "top_p": 0.7,       # 按需添加
        "frequency_penalty": 0 # 按需添加
    }
```

## 2. 关于`max_tokens`说明

平台提供的 LLM 模型中，

* max\_tokens 限制为 `16384`的模型：:
  * deepseek-ai/DeepSeek-R1
  * Qwen/QVQ-72B-Preview
  * deepseek-ai/DeepSeek-R1-Distill-Qwen-32B
  * deepseek-ai/DeepSeek-R1-Distill-Qwen-14B
  * deepseek-ai/DeepSeek-R1-Distill-Qwen-7B
  * deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B
* max\_tokens 限制为 `8192`的模型：:

  * Qwen/QwQ-32B-Preview
* max\_tokens 限制为 `4096`的模型：

  * 除上述提到的其他 LLM 模型的

如有特殊需求，请发送邮件至 [contact@siliconflow.com](mailto:contact@siliconflow.com)。

## 3. 关于`context_length`说明

不同的 LLM 模型，`context_length`是有差别的，具体可以在[模型广场](https://cloud.siliconflow.com/models)上搜索对应的模型，查看模型具体信息。

## 5. 语音模型中，对用户自定义音色有时间音质要求么

* cosyvoice2 上传音色必须小于 30s

为保证生成语音效果，建议用户上传音色为：时间 8～10s 左右，发音吐字清晰，没有杂音/背景音。

## 6. 模型输出截断问题

可以从以下几方面进行问题的排查：

* 通过 API 请求时候，输出截断问题排查：
  * max\_tokens 设置：max\_token 设置到合适值，输出大于 max\_token 的情况下，会被截断，deepseek R1 系列的 max\_token 最大可设置为 16384。
  * 设置流式输出请求：非流式请求时候，输出内容比较长的情况下，容易出现 504 超时。
  * 设置客户端超时时间：把客户端超时时间设置大一些，防止未输出完成，达到客户端超时时间被截断。
* 通过第三方客户端请求，输出截断问题排查：
  * CherryStdio 默认的 max\_tokens 是 4096，用户可以通过设置，打开“开启消息长度限制”的开关，将 max\_token 设置到合适值

## 7. 模型使用过程中返回 429 错误排查

可以从以下几方面进行问题的排查：

* 普通用户：检查用户等级及模型对应的 Rate Limits（速率限制）。如果请求超出 Rate Limits，建议稍后再尝试请求。
* 专属实例用户：专属实例通常没有 Rate Limits 限制。如果出现 429 错误，首先确认是否调用了专属实例的正确模型名称，并检查使用的 api\_key 是否与专属实例匹配。

## 8. 已充值成功，仍然提示账户余额不足

可以从以下几方面进行问题的排查：

* 确认使用的 api\_key 是否与刚刚充值的账户匹配。
* 如果 api\_key 无误，可能是充值过程中存在网络延迟，建议等待几分钟后再重试。


# 流式输出
Source: https://docs.siliconflow.com/cn/faqs/stream-mode



## 1. 在 python 中使用流式输出

### 1.1 基于 openai 库的流式输出

在一般场景中，推荐您使用 openai 的库进行流式输出。

```python
from openai import OpenAI

client = OpenAI(
    base_url='https://api.ap.siliconflow.com/v1',
    api_key='your-api-key'
)

# 发送带有流式输出的请求
response = client.chat.completions.create(
    model="deepseek-ai/DeepSeek-V2.5",
    messages=[
        {"role": "user", "content": "DeepSeek 发布，对大模型领域意味着什么？"}
    ],
    stream=True  # 启用流式输出
)

# 逐步接收并处理响应
for chunk in response:
    if not chunk.choices:
        continue
    if chunk.choices[0].delta.content:
        print(chunk.choices[0].delta.content, end="", flush=True)
    if chunk.choices[0].delta.reasoning_content:
        print(chunk.choices[0].delta.reasoning_content, end="", flush=True)
```

### 1.2 基于 requests 库的流式输出

如果您有非 openai 的场景，如您需要基于 request 库使用 siliconcloud API，请您注意：
除了 payload 中的 stream 需要设置外，request 请求的参数也需要设置 stream = True, 才能正常按照 stream 模式进行返回。

```python
from openai import OpenAI
import requests
import json
   
url = "https://api.ap.siliconflow.com/v1/chat/completions"
   
payload = {
        "model": "deepseek-ai/DeepSeek-V2.5", # 替换成你的模型
        "messages": [
            {
                "role": "user",
                "content": "DeepSeek 发布，对大模型领域意味着什么？"
            }
        ],
        "stream": True # 此处需要设置为 stream 模式
}

headers = {
        "accept": "application/json",
        "content-type": "application/json",
        "authorization": "Bearer your-api-key"
    }
   
response = requests.post(url, json=payload, headers=headers, stream=True) # 此处 request 需要指定 stream 模式
# 打印流式返回信息
if response.status_code == 200:
    full_content = ""
    full_reasoning_content = ""

    for chunk in response.iter_lines():
        if chunk:
            chunk_str = chunk.decode('utf-8').replace('data: ', '')
            if chunk_str != "[DONE]":
                chunk_data = json.loads(chunk_str)
                delta = chunk_data['choices'][0].get('delta', {})
                content = delta.get('content', '')
                reasoning_content = delta.get('reasoning_content', '')
                if content:
                    print(content, end="", flush=True)
                    full_content += content
                if reasoning_content:
                    print(reasoning_content, end="", flush=True)
                    full_reasoning_content += reasoning_content
else:
    print(f"请求失败，状态码：{response.status_code}")

```


# 隐私政策
Source: https://docs.siliconflow.com/cn/legals/privacy-policy

更新日期：2025 年 03 月 31 日

欢迎使用 SILICONFLOW TECHNOLOGY PTE.LTD. 的高价值生成式人工智能平台（" **SiliconFlow** "或"**我们**"）。我们非常重视保护用户（"**您**"）的个人数据。当您注册、登录并使用通过 [https://siliconflow.com](https://siliconflow.com)（"**平台**"）提供的服务（"**服务**"）时，我们将根据本政策收集和存储相关信息。

我们希望通过本隐私政策向您介绍我们如何处理您的个人数据。在您开始使用我们的服务之前，**请务必仔细阅读并理解本政策，以确保您在继续使用之前完全理解并同意。如果您不同意本隐私政策，您应停止使用服务。当您选择使用服务时，将被视为您同意并承认我们按照本隐私政策处理您的相关信息。**

### 修订

为了向您提供更好的服务，我们的平台和服务将定期更新和调整。我们也将及时修订本隐私政策。我们可能会及时修订本隐私政策，这些修订构成隐私政策的一部分并具有同等法律效力。

隐私政策更新后，我们将在平台上发布更新版本，并通过网站公告或其他商业合理方式，在更新条款生效前，尽合理最大努力通知您，以便您能够及时了解本隐私政策的最新版本。对于重大变更，我们将提供更显著的通知（包括但不限于电子邮件、短信、系统消息或浏览页面上的特别提醒），以说明隐私政策的具体变更。在我们发出通知且修订后的隐私政策生效后，您继续访问或使用我们的服务，将构成您对修订后的隐私政策的接受。

### 联系我们

如果您对本隐私政策有任何具体问题或关切，或者对您的个人数据如何被我们收集、使用、披露和/或处理有任何疑问或需要进行投诉，请通过 [contact@siliconflow.com](mailto:contact@siliconflow.com) 与我们联系。

### 概述

本隐私政策将帮助您了解：

1. 定义

2. 我们如何收集和使用您的个人数据

3. 互动数据

4. Cookie 和类似技术的使用

5. 我们如何共享您的个人数据

6. 第三方链接及第三方对个人数据的收集

7. 我们如何保留您的个人数据

8. 您的个人数据权利和选择

9. 个人数据的保护

10. 个人数据的准确性

11. 第三方无执行权

## 1.  定义

1.1  在本隐私政策中，以下词语和表达应具有以下分别赋予的含义：

"**数据保护法**"：指任何司法管辖区中与个人数据的收集、披露、使用和/或处理相关的所有适用法律和法规，包括但不限于 PDPA 及其所有现行及未来的修正案和附属立法。

**"PDPA"**：指新加坡 2012 年个人数据保护法，包括其所有现行及未来的修正案和附属立法。

"**个人数据**"：指关于个人的数据，无论其是否真实，该个人可以（a）从该数据本身被识别；或（b）从该数据和其他一方可能拥有或可能获得访问权限的其他信息中被识别。

"**处理**"，就个人数据而言，指对个人数据进行的任何操作或一系列操作，包括但不限于记录、持有、组织、调整、修改、检索、合并、传输、擦除或销毁，且"处理"应作相应解释。

1.2  本隐私政策中未定义的任何大写术语应具有隐私政策中赋予它们的含义。

## 2.  我们如何收集和使用您的个人数据

当您访问我们的服务时，我们可能会出于以下目的收集和使用您的以下个人数据：

2.1  **您提供的信息**

a.  **注册并登录平台账户**。您需要通过使用第三方平台账户来注册和登录平台。如果您使用另一个平台的账户登录平台，您授权我们从您的其他平台账户获取相关信息，例如来自\[Google 和 GitHub]等第三方平台的账户/账户信息（包括但不限于您的姓名、头像以及您授权的任何其他信息）。

b.  **订阅和购买服务**。当您在我们的平台上进行购买或订阅付费服务时，我们将收集与您的购买相关的信息（这些信息可能直接来自您，也可能来自我们合作的第三方支付服务提供商（例如 Stripe），用于验证您的交易并处理您的交易。这可能包括您的信用卡详细信息、银行账户详细信息、银行对账单、账单地址、您与我们之间的付款和订单，以及您通过平台购买的其他服务的详细信息。

c.  **调查和在线活动**。当您参与我们平台上的调查或抽奖活动时，我们可能会保留您的账户 ID、姓名、地址、手机号码、职务以及服务使用情况等信息。这些信息将用于与您联系、验证您的身份，并根据具体活动的规则为您提供奖励（如适用）。

2.2  **我们自动收集的信息**

a.  **服务的安全与运营**。为了维护我们服务的安全和稳定运行，保护您、其他用户或公众的合法权益免受损失，确保我们服务的正常运行和运营安全，以及防止网络攻击和入侵风险，我们将收集确保我们服务正常运行和网络安全所必需的信息。这些信息包括但不限于设备信息（如分辨率、时区和语言）、网络接入方式和类型信息以及网页浏览记录。

b.  **服务改进**。为了提升用户体验并确保使用安全，我们可能会记录网络日志信息，以及使用我们平台及相关服务的频率、崩溃数据、使用场景和相关性能数据等信息。这些信息将用于优化服务体验并提升产品质量。

c.  **故障排除**。我们可能会收集您在使用我们平台及相关服务过程中生成的用户咨询记录、故障报告记录以及故障排除过程信息（如通讯或通话记录）。这些信息将用于及时响应您的帮助请求并提升服务质量。

d.  **通知和营销信息**。我们可能会通过短信或电话向您发送有关您可能感兴趣的我们的服务、功能或活动的商业信息。如果您不希望接收此类信息，您可以通过短信或电子邮件取消订阅，或者直接联系我们取消订阅。

2.3  **我们从第三方收集的信息**

为了向您提供更优质、更优化、更个性化的服务，或者与您共同提供服务，或者检测欺诈信息，我们的关联公司和合作伙伴可能会根据法律要求、与您的协议或经您同意的情况下，与我们共享您的信息。我们将根据相关法律法规，并在身份验证功能所必需的范围内，采用行业标准方法并尽最大商业努力保护您的个人数据的安全。

## 3  交互数据

通过本平台提供的服务（不包括第三方服务）生成或处理的数据，包括但不限于通过输入、反馈、修改、处理、存储、上传、下载、分发等手段，与开源模型、第三方网站、软件、应用程序或服务相关的数据，均应视为您的业务和客户数据（"**互动数据**"）。

您理解并同意，您应根据自身需求负责存储您的互动数据。我们仅根据相关法律法规要求或特定服务规则提供数据存储服务。您理解并进一步同意，除非法律法规另有规定或服务规则另有约定，我们没有义务存储您的互动数据，我们也不会对您的数据存储工作或结果承担任何责任。

如果互动数据包含个人数据，作为中立的技术服务提供商，我们将仅严格根据您的指示处理您的互动数据。您有义务按照法律要求履行与互动数据中包含的个人数据处理相关的义务。

## 4.  Cookies 和类似技术的使用

Cookie 和类似技术在互联网中是常见且广泛使用的。当您使用我们的平台时，我们可能会使用相关技术向您的设备发送一个或多个 Cookie 或匿名标识符，以收集和存储您的账户信息、搜索历史信息以及登录状态信息。Cookie 和类似技术可以帮助您跳过反复填写账户信息和输入搜索内容的步骤和流程。它们还可以帮助我们提高服务效率并增强登录和响应速度。

您可以通过修改浏览器中的设置来接受或拒绝 Cookie。然而，请注意，如果您禁用 Cookie，您可能无法享受到最佳的服务体验，某些功能的可用性可能会受到影响。

## 5.  我们如何共享您的个人数据

5.1  您承认并同意，您向我们提供的个人数据可能会披露和/或转移给以下第三方，并且这些第三方可能会在新加坡境内或境外使用或处理这些个人数据，以实现上述目的或法律允许/要求的其他目的：

a.  **我们的关联公司。** 我们可能会与我们的关联公司共享您的个人数据，以便我们能够为您提供服务。

b.  **服务提供商。** 我们聘请第三方服务提供商来运营和维护我们的服务、存储数据并提供相关服务。我们可能会与这些服务提供商共享您的个人数据，以确保您能够访问和使用我们的应用程序和服务。例如：

* i.  **第三方支付服务提供商**：我们使用如 Stripe 等第三方支付服务提供商来处理您的付款。

* ii. **客户服务提供商**：我们使用第三方客户服务提供商来及时处理您的投诉和建议。

* iii. **数据分析服务提供商**：我们使用数据分析服务提供商来分析我们的服务使用情况并提升用户体验。

c.  **政府和监管机构。** 我们可能会与第三方共享您的个人数据，包括执法机构以及新加坡境内外的政府或监管机构，如果适用法律要求（包括响应有效的法律程序，如搜查令或法院命令），或者与我们的服务相关，或者我们有其他合法利益需要这样做。

d.  **我们业务的购买者和继任者。** 在合并、重组、解散或其他出售或转让所有权的情况下，我们可能会与任何购买者或继任者共享您的个人数据。

e.  **我们的顾问，包括审计师和律师。** 在寻求专业建议的过程中，我们可能会与我们的顾问共享或披露您的个人数据。

## 6.  第三方链接及第三方对个人数据的收集

6.1  平台可能会不时包含引导到我们关联公司、广告商或其他第三方网站的链接（"**第三方网站**"）。我们服务中的某些功能和特性（如支付功能）可能由第三方（如支付服务提供商）提供（这些功能和特性称为"**第三方服务**"）。第三方网站和第三方服务由第三方（"**第三方服务提供商**"）运营。当您访问或使用这些第三方服务，或点击链接到第三方网站时，您的个人数据可能会被这些第三方服务提供商直接收集。

6.2  由于这些第三方网站和第三方服务并非由我们所有或运营，我们不承担任何责任或义务，也不对这些第三方网站和第三方服务，或这些第三方服务提供商对您的个人数据的收集承担责任。您访问这些第三方网站和第三方服务，以及向这些第三方服务提供商提供个人数据，完全由您自行承担风险。在向这些第三方服务提供商提供任何个人数据之前，请仔细查看适用于这些第三方网站和第三方服务的隐私政策。

6.3  通过访问或使用第三方网站和/或第三方服务，或向第三方服务提供商提供您的个人数据，您承认并同意：

a.  您已阅读并理解这些第三方服务提供商的隐私政策，并同意根据其隐私政策，由这些第三方服务提供商收集、使用、披露和/或处理您的个人数据；

b.  我们无法控制这些第三方服务提供商，您的个人数据可能被收集、使用、披露和/或处理的方式和目的，仅由作为数据控制者（根据适用的数据保护法定义）的这些第三方服务提供商决定；

c.  在法律允许的最大范围内，我们不对您因使用任何第三方网站和/或第三方服务，或任何第三方服务提供商对您的个人数据的收集、使用、披露和/或处理而可能遭受的任何责任、损失或损害承担责任。

## 7.  我们如何保留您的个人数据

我们可能会在为实现收集个人数据的目的所必需的期间内保留您的个人数据，或者根据适用法律的要求或允许进行保留。

一旦我们合理认为保留个人数据不再服务于收集该个人数据的目的，并且不再出于法律或商业目的而有必要时，我们将停止保留您的个人数据或移除可将数据与您关联的手段。

## 8.  您的个人数据权利和选择

8.1  **撤回同意**

a.  您可以通过向我们的数据保护官提交请求（通过上述提供的联系方式发送电子邮件），撤回您对我们收集、使用、披露和/或处理您的个人数据的同意，以停止上述列出的任何或所有目的。

b.  在收到您书面撤回同意的请求后，我们可能需要合理的时间来处理并回应您的请求。

c.  虽然我们尊重您撤回同意的决定，但请注意，根据您请求的性质和范围，我们可能无法继续为您提供对我们的服务的访问。在这些情况下，我们将在完成您的请求处理之前通知您。

d.  请注意，撤回同意并不影响我们在适用法律允许或要求的情况下，继续收集、使用、披露或处理您的个人数据的权利。

8.2  **访问和更正您的个人数据**

a.  如果您希望提出

* i.  访问请求，以获取我们持有的关于您的个人数据副本，或了解我们在您请求日期之前的过去一年中如何使用或披露您的个人数据的信息；或

* ii. 更正请求，以更正或更新我们持有的关于您的任何个人数据。

> 您可以通过发送电子邮件至 [contact@siliconflow.com](mailto:contact@siliconflow.com) 向我们提交请求，具体联系方式请参阅上述提供的信息。

b.  请注意，对于您的访问请求，我们可能会收取合理的费用。如果会收取费用，我们将在处理您的请求之前告知您。

c.  我们将在合理的时间内尽快回应您的请求。如果我们无法在收到您的请求后的三十（30）天内回应您的请求，我们将在收到您的请求后的三十（30）天内以书面形式告知您我们能够回应您请求的时间。如果我们无法向您提供任何个人数据或按照您的要求进行更正，我们通常会告知您无法这样做的原因（除非根据适用法律我们无需这样做）。

## 9.  个人数据的保护

9.1  我们将采取适当的管理、物理和技术措施，以保护您的个人数据免受未经授权的访问、收集、使用、披露、复制、修改、处置或类似风险，以及存储个人数据的任何存储介质或设备的丢失。

9.2  然而，您应该意识到，没有任何一种通过互联网传输的方法或电子存储的方法是完全安全的。尽管不能保证安全，但我们致力于保护您的个人数据的安全，并不断审查和加强我们的安全措施。

## 10. 个人数据的准确性

10.1  当您向我们提供个人数据时，您应确保这些个人数据是准确的。您还应定期查看您的个人数据，并在您的个人数据有任何变化或更新时通知我们，以便我们不会持有任何关于您的不准确的个人数据。

10.2  您可以随时通过登录您的账户来查看和更新您的个人数据。

## 11. 第三方无执行权

11.1  非本隐私政策一方的个人无权执行本隐私政策下的任何条款。


# 用户协议
Source: https://docs.siliconflow.com/cn/legals/terms-of-service

更新日期：2025 年 03 月 31 日

本使用条款（“**协议**”）构成 SILICONFLOW TECHNOLOGY PTE. LTD.（“**SiliconFlow**”、 “**我们的**”）与您（“**用户**”或“**您**”）之间具有约束力的协议，规范您对平台（定义见下文）和服务（定义见下文）的访问和使用。服务不向位于中国大陆地区的用户提供，中国用户可以通过 [https://siliconflow.cn](https://siliconflow.cn) 访问我们的服务。请注意，本协议包含并通过引用纳入我们的隐私政策，您可以在 [https://docs.siliconflow.com/en/legals/privacy-policy](https://docs.siliconflow.com/en/legals/privacy-policy) 查看（“**隐私政策**”）以及用户协议（定义见下文）。

您承认本协议与您和 SiliconFlow 之间书面签署的协议具有同等效力。通过访问或使用平台和服务的任何部分，您确认并同意：（i）您已阅读、理解并同意受本协议、隐私政策和用户协议条款的约束；（ii）您已达到根据您所在地区的法律法规与 SiliconFlow 订立具有约束力合同的法定年龄，并具备相应的缔约能力。**如果您不同意受本协议、隐私政策和用户协议条款的约束，未达到法定年龄，或没有缔约能力，您不得访问或使用平台和服务。**

我们保留随时修订本协议，或修订、发布新的文档和其他条款和条件的权利，这些条款和条件将规范您对平台和服务（包括平台和服务中的新功能或新功能）的访问和使用（统称“**用户协议**”）。我们可能会使用商业上合理的通知方式，例如通过平台向您发送推送通知，来告知您此类修订。在我们发出通知后，您继续访问或使用平台和服务，即表示您接受修订后的协议、修订后的用户协议或新的用户协议（视具体情况而定）。

## 1. **定义**

1.1 在本协议中，以下词语和表达应具有各自被赋予的含义：

**“账户”**具有**第 5.1 条**中赋予的含义。

**“关联方”** 就一方而言，指控制该方、被该方控制或与该方共同受控的任何实体（其中“控制”包括其相关含义，如“被控制”、“控制”和“共同控制”，指直接或间接拥有指导或导致指导公司管理政策的权力，无论是通过拥有表决权证券、合同还是其他方式）。

**“平台”** 指 SiliconFlow 提供的多种版本（包括但不限于网页版、API 和移动应用程序）的平台，并向用户开放，供其访问服务。

**“文档”** 指 SiliconFlow 提供或发布的任何和所有用户指引、指南、通知、操作规则、政策和说明或其他描述平台和服务的特点、功能或操作的文档，包括但不限于 SiliconFlow 不时对这些文档进行的任何修订、修改和更新。

**“错误”** 具有**第 4.2（c）条**中赋予的含义。

**“费用”** 具有**第 6.1 条**中赋予的含义。

**“反馈”** 具有**第 12（a）条**中赋予的含义。

**“不可抗力事件”** 指超出一方合理控制范围的任何情况，包括但不限于：(a) 火灾、风暴、闪电、洪水、干旱、地震或其他自然灾害或其他类似天灾；(b) 传染病或大流行病；(c) 恐怖袭击、内战、内乱或骚乱、战争、战争威胁或准备、武装冲突、制裁的实施、禁运，或外交关系的断绝；(d) 任何法律或任何政府机构采取的行动，包括但不限于对法律的变更，实施进出口限制、配额或禁令，或未能授予必要的许可或同意；(e) 火灾、爆炸或事故；(f) 任何劳资或贸易纠纷、罢工、工业行动或停工；(g) 供应商或分包商未能履约；以及 (h) 电力、煤气、水、电信（包括互联网）等公用事业服务的不可用、中断或故障。

**“政府机构”** 指在世界上任何地区对 SiliconFlow 或用户的事务有管辖权的任何政府、行政、法定、监管或自律的司法或仲裁机构或机构（包括其任何分支）。

**“恶意代码”** 指任何计算机代码、文件、脚本和程序，包括任何恶意软件和/或软件，其意图或已知是有害的、破坏性的、使系统失效的，或协助或启用盗窃、篡改、拒绝服务、未经授权披露或破坏或损坏数据的，包括病毒、蠕虫、间谍软件、广告软件、键盘记录器、特洛伊木马、勒索软件以及任何新型威胁。

**“知识产权”** 指专利、商标、服务商标、版权、技术诀窍、设计权、数据库权、软件权利、设计和发明权利、商业秘密、保密信息、商号和品牌、互联网域名、任何前述权利的任何申请（无论是待决、处理中或已颁发的）以及任何其他国家和任何形式、媒体或技术（无论是现在已知的还是以后开发的）的任何其他类似工业、知识产权或受保护权利。

**“交互数据”** 指通过本平台提供的服务生成或处理的数据（不包括第三方服务），包括但不限于通过输入、反馈、修改、处理、存储、上传、下载、分发等其他方式，与开源模型、第三方网站、软件、应用程序或服务相关的数据。

**“法律”** 指不时生效的任何适用的成文法、法规、附例、法令或附属立法，包括不时适用的普通法，以及任何适用的具有强制性和约束性的行业守则或标准。

**“维护”** 指为允许对平台或服务进行更新、升级、维修和维护而对平台或服务进行的任何计划内或紧急暂停或限制。

**“付款方式”** 具有第 6.5 条中赋予的含义。

**“支付服务提供商”** 具有第 6.6(a) 条中赋予的含义。

**“个人信息”** 指关于可从 (a) 该数据本身；或 (b) 该数据和其他一方可能拥有或可能获得访问权的其他信息中识别出个人的任何数据，无论其是否真实。

**“人员”** 具有第 10.6 条中赋予的含义。

**“注册用户”** 具有第 5.1 条中赋予的含义。

**“注册数据”** 具有第 5.4 条中赋予的含义。

**“奖励”** 具有**第 6.3 条**中赋予的含义。

**“服务”** 指 SiliconFlow 及其商业伙伴通过平台向用户提供的服务、功能、特性、信息和内容。为避免疑义，服务不包括第三方材料。

**“技术数据”** 指与平台或服务相关的系统特定数据、信息及其他技术数据。

**“期限”** 具有**第 13.1 条**中赋予的含义。

**“第三方账户”** 具有**第 5.3 条**中赋予的含义。

**“第三方材料”** 具有**第 9.1 条**中赋予的含义。

**“第三方软件”** 具有**第 8.1 条**中赋予的含义。

**“商标”** 具有**第 2.3 条**中赋予的含义。

**“不可用性”** 具有**第 4.2（c）条**中赋予的含义。

**“更新”** 指对平台或服务的软件组件进行的更新、漏洞修复、补丁、修正、修改、增强、新版本发布、引入新功能或特性，或移除或修改现有功能或特性。

**“用户协议”** 指 SiliconFlow 不时引入的文档和政策。

**“用户设备”** 具有**第 8.1 条**中赋予的含义。

**“用户过失”** 指任何因用户原因导致的无法访问或使用平台或服务的情况，包括但不限于：(i) 您违反本协议（包括用户协议）访问或使用平台和/或服务，(ii) 用户未遵守本协议第 3 条规定的用户义务和限制，(iii) 用户延迟履行或未履行其在本协议下的任何义务（包括付款），(iv) 用户的互联网连接问题，或 (v) 用户设备及其他由用户需要访问或使用平台或服务的硬件或软件组件的故障或不兼容，而这些组件并非由 SiliconFlow 提供。

“SiliconFlow 知识产权”具有**第 11.1 条**中赋予的含义。

“SiliconFlow 专有标记”具有**第 11.1（a）条**中赋予的含义。

## 2. **许可**

2.1 平台（包括文档和服务）归我们所有。在期限内，SiliconFlow 特此授予您一项有限的、可撤销的、非排他的、不可转让的、不可再许可的且不可转让的许可，以访问和使用平台和服务，但需遵守本协议的条款和条件，并且仅限于在新加坡使用。

2.2 平台和服务上可用的所有知识产权（交互数据和注册数据除外）归 SiliconFlow 所有或由许可方许可给 SiliconFlow。除本协议授予的有限许可外，您不会获得平台或服务的任何权利、所有权或利益。SiliconFlow 保留并保留其对平台和服务的全部权利、所有权和利益，包括其中的所有知识产权。

2.3 平台上使用和显示的商标、服务商标、商号和标识（“**商标**”）是 SiliconFlow（您提供的注册数据中包含的商标除外）及其他人的注册和未注册商标。平台上任何内容均不应被解释为授予您使用平台上商标的任何许可或权利，未经 SiliconFlow 或任何其他适用的商标所有者事先书面许可，不得使用。

## 3. **用户义务和限制**

3.1 您应遵守本协议、用户协议、文档以及所有适用法律，访问和使用平台和服务。

3.2 您确认、声明并保证将遵守本协议第 7 条规定的义务。

3.3 您不得使用平台或服务：

a. 用于任何非法目的或犯罪活动；或

b. 发布、上传、发布、提交、传播、推广或以其他方式提供任何：

* i. 非法、骚扰性、诽谤性、辱骂性、威胁性、有害、粗俗、淫秽、色情、不雅、假冒、欺诈性、被盗、有害或其他令人反感的内容或材料；

* ii. 鼓励构成犯罪的行为，或违反任何适用法律、法规或行为准则的材料；

* iii. 用于广告目的或其他未经授权的材料；

* iv. 侵犯或违反他人知识产权（包括但不限于未经所有者许可制作、传输或存储受知识产权保护的材料的电子副本）、公开权或隐私权或其他个人权利的材料；或

* v. SiliconFlow 认为令人反感或限制、阻碍他人使用或享受平台或服务，或可能使 SiliconFlow 或其用户遭受任何伤害或责任的材料。

3.4 在使用平台和服务时，您不得：

a. 假冒任何个人或实体，或虚假声明、歪曲或误导您与任何个人或实体的关联；

b. 将本服务提供或通过本服务提供的任何内容（包括任何标题信息、关键词或其他元数据）用于任何机器学习和人工智能训练或开发目的，或用于任何旨在识别自然人身份的技术；

c. 收集或获取本服务上的任何个人信息，包括但不限于其他用户的名字；

d. 尝试未经授权访问或以其他方式干扰平台或服务的任何部分的性能、运行或功能，或通过平台访问的任何计算机设施；

e. 将平台、服务或文档（或其任何部分）提供给他人，或为他人利益使用这些资源；

f. 出租、租赁、出借、出售、转售、转授权、转让、分发、发布或以其他方式使任何第三方能够使用平台或服务（或其任何部分），包括文档，或将平台或服务纳入服务局、分时或外包服务中；

g. 干扰或破坏平台或服务的完整性、性能、运行或功能，或其上包含的任何信息和内容；

h. 复制、改编、修改、制作衍生作品、转让、公开展示、传输或以其他方式利用平台或服务，包括其任何功能或特性；

i. 使用任何手动或自动软件、设备或其他流程（包括但不限于蜘蛛、机器人、抓取工具、爬虫、化身、数据挖掘工具或类似工具）来“抓取”、收集或下载平台或服务上的任何信息和数据；

j. 访问平台或服务以构建竞争产品或服务，或以其他方式与 SiliconFlow 竞争；

k. 反编译、反汇编或以其他方式试图推导或获取平台或服务或其任何部分的源代码或基础设施；

l. 尝试探测、扫描或测试平台或服务、任何 SiliconFlow 系统或网络的漏洞，或违反任何安全或认证措施，或以其他方式试图对平台或服务或 SiliconFlow 的服务性能进行基准测试；

m. 通过平台或服务上传、存储、传输或使任何恶意代码可用；

n. 删除、修改或掩盖平台或服务上的任何商标或任何版权、商标、专利或其他知识产权通知，包括其任何副本上的通知；

o. 为 SiliconFlow 的任何竞争对手（包括其任何员工或承包商）提供对平台或服务（或其任何部分）的访问或使用，包括只读访问、通过您的身份和密码信息直接访问或其他方式；

p. 将平台或服务用于任何商业目的，包括但不限于广告、销售或提供销售商品或服务，或进行任何培训、活动或课程。

3.5 您承认并同意，SiliconFlow 保留权利，但没有义务：

a. 监控您对平台或服务的访问和使用，检查、审查和/或控制平台上或通过平台发生的任何活动、内容或信息，以确保您遵守本协议，或遵守 SiliconFlow 根据适用法律或法院或其他政府机构的命令或要求所承担的义务；

b. 调查并依法起诉违反本协议的行为，报告平台上或通过服务发生的任何可疑或非法活动，并与执法机构合作起诉违反本协议的用户；

c. 随时且无需事先通知，以任何理由或无理由（包括但不限于 SiliconFlow 自行判断您的任何行为或操作违反本协议或适用法律，对平台、服务或其用户造成损害，或遵守法院或其他政府机构的命令或要求）终止您根据本协议获得的许可，并移除或禁用您对平台或服务（或其任何部分）的访问和使用。

## 4. **可用性**

4.1. SiliconFlow 将尽商业上合理的努力使平台和服务对您可用，并确保平台和服务符合新加坡法律。

4.2 尽管有上述规定，您承认并同意：

a. 由于适用的新加坡法律和相关技术参考指南可能会不时变更，SiliconFlow 不能保证您对平台和/或服务的访问和使用将始终符合适用的新加坡法律；

b. 平台和/或服务的可用性和性能可能会因多种 SiliconFlow 无法控制的因素而有所不同，包括但不限于互联网的稳定性以及电信网络的中断。SiliconFlow 不对平台和/或服务的性能（包括但不限于质量、速度、服务水平或效率）、正常运行时间或可用性，或您对平台和/或服务的访问和使用将不间断、无错误或满足您的需求和要求作出任何明示、暗示、法定或其他保证；

c. 对于平台和/或服务中的任何错误或中断（“**错误**”），或您因任何原因无法访问或使用平台和/或服务（或其任何部分）（“**不可用性**”），以及由此造成的任何损失或损害，SiliconFlow 概不负责，包括但不限于以下情况：

* i. 用户过失；

* ii. 维护；

* iii. 不可抗力事件；

* iv. 法律变更或法院或其他政府机构的命令或要求；

* v. 根据本协议暂停或终止您的账户、对平台和/或服务的访问和/或使用；互联网、电信网络、电网故障或任何其他非 SiliconFlow 引起或超出其控制范围的原因。

4.3 您承认并同意，为进行更新，您对平台和/或服务的访问和/或使用可能会偶尔被暂停或限制。SiliconFlow 可在任何时间且无需给出任何理由或通知的情况下更新平台和/或服务，且对此不承担任何责任。您进一步同意，所有更新将成为平台或服务的一部分，并受本协议的所有条款和条件约束。

## 5. **用户账户**

5.1 为访问平台或服务，您需成为注册用户并通过账户使用相关功能。根据本协议，“**注册用户**”指在平台上注册账户以使用这些功能的用户。

5.2 要成为注册用户，您需通过第三方账户注册并登录。

5.3 SiliconFlow 允许您将账户与第三方服务账户（如 Google、Github 等）关联，或使用第三方账户访问平台或服务。本协议中“账户”包括“第三方账户”。

5.4 创建账户时，您同意：

a. 提供真实、准确、最新且完整的个人信息（“**注册数据**”）；

b. 维护并及时更新注册数据，确保其真实、准确、最新且完整；

c. 不使用虚假身份或信息创建账户，也不代替他人创建账户。

5.5 您承认并同意，负责保持账户的保密和安全，不允许他人使用您的账户访问平台和服务。若怀疑账户保密性受损或有未经授权的使用或其他安全漏洞，应立即通过 [contact@siliconflow.com](mailto:contact@siliconflow.com) 通知 SiliconFlow。

5.6 您承认并同意，任何通过您的账户访问或使用平台或服务的行为、账户下的所有操作、以及与账户相关的信息、数据或通信都将归因于您。即使您未授权这些行为，您也将被视为执行了这些行为，并对所有行为负全责。SiliconFlow 有权将这些行为视为您所为，并追究您的责任。您同意就任何与您的账户相关的行为给 SiliconFlow 造成的损失进行全额赔偿。

5.7 SiliconFlow 对因账户被盗、您泄露账户信息或他人使用您的账户而引起的任何损害或损失不承担责任。

5.8 SiliconFlow 保留要求您提供额外注册数据、更改密码、暂时或永久暂停或终止账户、或限制您访问和使用平台或服务的权利，可在任何时间、基于任何理由且无需通知，包括但不限于：

a. 您提供的注册数据不真实、不准确、不是最新的或不完整；

b. SiliconFlow 有合理理由认为您违反或即将违反本协议、适用法律等，或您的账户可能已被盗用；

c. 您账户下的活动可能对 SiliconFlow 或用户造成损害或损失，或侵犯第三方权利；

d. 您拒绝提供继续使用平台或服务所需的信息；

e. 应执法机构或其他政府机构的要求；

f. 解决技术或安全问题，或进行维修、维护、引入新功能或服务。

5.9 SiliconFlow 对因暂停或终止您的账户而使您遭受的任何损失不承担责任。

5.10 您同意，若您曾被 SiliconFlow 禁止使用平台和服务，则不再创建账户或使用平台和服务。

5.11 您承认并同意，与平台通信的数据（包括用户访问数据、账户数据和交易数据）可能会被监控、捕获、记录并传输给当局，以符合当地法律要求，且无需进一步通知。

5.12 您负责保持用户设备和平台访问的安全。移除用户设备官方操作系统施加的软件限制可能会使设备易受恶意代码攻击，影响平台和/或服务的正常功能。对于因账户、安全凭证或用户设备的丢失、泄露、被盗或未经授权使用而造成的任何损害，SiliconFlow 概不负责。

## 6. **费用和支付**

6.1 您需要向我们支付费用以访问或使用服务。为了访问和使用这些服务，您必须全额支付您已接收和使用的服务的相应费用（“**费用**”）。费用将在您接收我们服务之前通过平台向您展示。您需负责所有适用的税费，我们会在需要时收取税费。一旦您选择接受费用并接收我们的服务，这些费用将在您接收服务后立即到期并由您支付。费用可能是定期的或基于使用的。如果这些费用被指定为定期或基于使用，您同意我们可以根据您在初次购买时指定的付款方式定期收取费用。如果您未全额支付费用，SiliconFlow 可能会暂停或限制您进一步使用我们的平台和/或服务。

6.2 SiliconFlow 保留根据**第 4.2（c）条**所述的错误向您追回任何应缴费用的权利。

6.3 您承认并同意：

a. 除非我们在与您签订的单独合同中明确另行同意，我们可以在任何时候调整或增加访问或使用服务的任何费用。对于 SiliconFlow 可能提供的额外服务或服务功能，可能会收取额外费用。在这种情况下，我们将在收取额外费用之前通知您。如果我们因服务收取额外费用，您将有机会在被收费之前查看并接受将被收取的额外费用。如果您不接受任何此类额外费用，我们可能会停止您访问服务或功能。

b. 虽然 SiliconFlow 可能在平台中提供一种或多种付款方式，但 SiliconFlow 不运营或提供任何支付服务。每种付款方式背后的支付服务由相关服务提供商（“**支付服务提供商**”）向您提供，您使用这些支付服务可能会受到您与这些支付服务提供商签订的单独协议或安排的约束，而 SiliconFlow 并非这些协议的一方。SiliconFlow 不对您可能欠银行、借记卡或信用卡公司或支付服务提供商的任何义务或责任负责，您应解除 SiliconFlow 在您与这些第三方之间的任何协议或安排下可能欠您的任何义务或责任。

c. SiliconFlow 不为您提供接受资金以执行或安排支付交易的服务；

d. SiliconFlow 不提供任何在线支付网关或相关服务；

e. SiliconFlow 不经营也不声称经营受新加坡《支付服务法 2019》监管的支付服务。因此，我们对您没有也不声称对您有任何此类义务（无论是合同义务还是其他义务）。您承认我们未获得新加坡《支付服务法 2019》的许可、批准或注册，您可能无法获得《支付服务法 2019》及相关附属立法、法规、通知、指南中规定的相关保护。

6.4 所有付款应以平台中为相关付费服务所指示的货币进行支付。

6.5 您需负责与付款相关的所有税费和交易费用。

6.6 未经我们书面同意或根据平台的其他相关政策，在付款义务产生后，付款不可取消，已支付的费用不予退还。

6.7 您负责核实向您收取的任何费用的准确性。如果您对任何费用有异议或不同意，必须在费用被收取之日起七（7）天内书面通知 SiliconFlow。如果您在七（7）天内未向我们发出此类通知，您将被视为已接受费用的准确性并放弃对费用提出异议的权利。SiliconFlow 对因差异或不准确而引起的所有损失概不负责。

6.8 如果您在购买服务时有任何问题，可以通过 [contact@siliconflow.com](mailto:contact@siliconflow.com) 联系我们。

## 7. **交互数据**

7.1 **本服务可能允许注册用户根据平台使用目的，在使用模型期间在开源模型、第三方网站、软件、应用程序或服务之间输入、提供反馈、进行更正、处理、存储、上传、下载或分发个人数据、视频、图像、音频、评论、问题以及其他内容、文件、数据和信息（统称为“交互数据”）。**

7.2 如果任何交互数据违反适用法律、法规或本协议，我们保留删除或暂停服务的权利。

7.3 关于您的交互数据，您在此确认、声明并保证：

a. 应我们的要求，您将就交互数据中包含的任何需要授权的个人信息或其他数据的来源和合法性提供书面解释或授权。如果您超出授权使用范围或期限，您应独自负责获得扩展或延长的授权；

b. 您的交互数据以及我们在本协议下对这些数据的使用不会违反任何适用法律或侵犯任何第三方权利，包括但不限于知识产权和隐私权；

c. 您的交互数据不包含政府机构视为敏感或机密的信息或材料，也不侵犯任何第三方的保密权；

d. 您不会通过本服务直接或间接上传或提供 14 岁以下儿童的个人信息；

e. 您的交互数据不包含裸露或其他具有性暗示的内容；仇恨言论、威胁或针对个人或群体的直接攻击；辱骂、骚扰、侵权、诽谤、粗俗、淫秽或侵犯隐私的内容；性别歧视、种族歧视、民族歧视或其他歧视性内容；宣扬自残或过度暴力的内容；虚假或冒名顶替的个人资料；非法内容或鼓励有害或非法活动的材料；恶意程序或代码；未经个人同意的个人信息；或垃圾邮件、机器生成内容、未经请求的消息或其他令人反感的材料；以及

f. 您向我们提供的所有交互数据均合法，不侵犯任何第三方的合法权益。

7.4 \*\*免责声明。\*\*我们不对任何交互数据负责或承担任何责任。您独自负责通过本平台或模型服务输入、修改、处理、存储、上传、下载、分发或以其他方式处理的所有交互数据。**除非法律另有要求，或在特定产品规则下达成一致，或在您请求提供技术支持以解决技术问题时需要，我们的技术服务将严格按照您的指示处理交互数据。我们不会访问您的交互数据。您承认并同意，我们和本平台仅作为交互数据的被动技术支持者或渠道。我们没有义务存储交互数据，未经授权不会使用或披露交互数据。此外，我们仅会按照适用法律并仅为了向您提供服务的目的使用您的交互数据。**

## 8. **互联网/用户设备/第三方软件**

8.1 您承认并同意，为访问和使用平台和服务，您需要具备互联网接入能力，并拥有符合文档中规定规格且能够接入互联网的计算设备（“用户设备”）。此外，某些不属于平台和服务组成部分的第三方软件（包括用户设备的操作系统和网络浏览器）（“第三方软件”）可能需要正确安装在用户设备上，以便您访问和使用平台和服务。您承认 SiliconFlow 无法控制此类第三方软件的最终用户许可协议的条款和条件，并且在任何情况下都不应被视为参与您与任何第三方之间的任何协议或安排。您应自行负责以自己的费用、开支和风险获取互联网接入、用户设备，并签订和维护第三方软件的最终用户许可协议。您对单独获取的第三方软件和/或用户设备的使用应符合任何适用的条款和条件。SiliconFlow 不对您因任何不归因于 SiliconFlow 的原因（包括您无法接入互联网，或用户设备或第三方软件的任何问题）而无法访问平台和/或服务负责。

## 9. **第三方材料**

9.1 SiliconFlow 可能会在平台或服务上展示、包含或提供第三方内容，或提供链接至第三方网站或服务（统称为“**第三方材料**”）。您承认并同意，您通过平台或服务访问任何第三方材料的风险完全由您自行承担。

9.2 不影响前述条款的前提下，您承认并同意：

a. SiliconFlow 可能会监控和审查此类第三方材料，但没有义务这样做，并且不对这些第三方材料负责，包括其准确性、完整性、及时性、有效性、版权合规性、合法性、体面性、质量或任何其他方面；

b. SiliconFlow 不承担也不会对您或任何其他个人或实体对任何第三方材料承担任何责任；

c. 提供第三方材料及其链接仅是为您提供便利，您访问和使用它们完全由您自行决定，并受这些第三方的条款和条件约束；

d. SiliconFlow 不保证这些第三方材料的持续可用性，并且可能会自行决定在任何时候停止展示、包含或提供这些第三方材料，而无需对您承担任何责任；

e. SiliconFlow 不做任何陈述或保证，也不会对您因使用第三方材料而可能遭受的任何损害、责任、损失（包括任何数据或利润的损失），或通过这些材料完成的任何交易，或与任何第三方签订的任何合同负责。

9.3 您应赔偿 SiliconFlow 因任何第三方因您使用、集成和/或与第三方材料及相关数据进行接口而对 SiliconFlow 采取的任何行动或提出任何索赔而产生的一切成本、损失、责任和损害。

## 10. **免责声明、责任限制和赔偿**

10.1 您承认并同意，在适用法律允许的最大范围内，平台和服务由 SiliconFlow 按“原样”和“可用性”提供，包含所有缺陷。在不影响第 10 条的普遍性的前提下，为澄清起见，在适用法律允许的最大范围内，SiliconFlow 不对平台和服务做出任何陈述、保证或承诺，无论是明示的、暗示的、法定的还是以其他方式施加的，并明确拒绝所有其他任何形式的保证、陈述和条件，无论是明示的、暗示的、法定的还是其他方式，与平台和服务和/或使用平台和服务可能（或可能不）实现的结果有关，包括但不限于所有适销性、第三方权利、所有权、满意质量、特定用途适用性、完整性、非侵权性、准确性、正确性、可靠性、及时性或有效性、法律合规性，以及任何从交易过程、使用习惯或贸易中产生的保证。SiliconFlow 也不保证错误将得到纠正，或平台或服务将不受幻觉、错误和/或平台或服务不是最新的、准确的或完整的。

10.2 不影响**第 10 条**的普遍性，SiliconFlow 不代表和保证：
a. 平台或服务将满足您的需求；
b. 平台或服务的使用将被法律允许或继续被允许；
c. 平台或服务中包含的所有数据和/或信息的准确性、及时性、充分性、商业价值或完整性；
d. 平台或服务，或通过平台或服务获得的任何材料或信息将不间断、安全或无错误或遗漏地提供；
e. 平台或服务或通过平台或服务获得的任何材料不受任何恶意代码的影响；或
f. 您通过平台或服务传输的任何数据或信息（包括交互数据）的安全性。在这方面，您承认并同意，您理解通过平台或服务传输的任何材料或信息可能被未授权的第三方访问，并接受此类事件发生的风向，且不会因此追究 SiliconFlow 的责任。
10.3 在任何情况下，SiliconFlow 均不对您负责：
a. 任何收入、收益、利润、销售、合同、商业机会、业务或预期节支的损失；
b. 任何商誉或声誉损失；
c. 任何数据丢失或损坏；或
d. 任何附带、间接、惩罚性、特殊、纯粹经济损失、精神痛苦或其他间接损失；

无论基于保证、合同、侵权、法规、严格责任还是其他理论，即使 SiliconFlow 已被告知可能发生此类损害或损失，且这些损害或损失是由以下原因引起、导致或与以下原因有关：

a. 您因任何原因无法使用平台或服务；
b.  您依赖通过平台或服务提供的任何材料或信息；
c.  因通过平台和服务购买或获取的任何商品、数据、信息或服务，或通过平台和服务接收的消息而产生的替代商品或服务的采购成本；
d.  您的数据或信息（包括交互数据）的任何未经授权的访问或篡改；
e.  平台上任何第三方的陈述或行为；或
f.  与平台和服务有关的任何其他事项。

10.4 除因 SiliconFlow 的过失导致的死亡或人身伤害外，在法律允许的最大范围内，SiliconFlow 不对您负责任何死亡或人身伤害，无论其原因和责任理论如何，且与本协议或您使用平台和/或服务有关，或由您使用或无法使用平台或服务导致或与之有关。

10.5 在任何情况下，SiliconFlow 因本协议而产生的累计责任不得超过您在索赔提出前的一年期间内为付费服务向 SiliconFlow 支付的金额。

10.6 应赔偿、抗辩并使 SiliconFlow、我们的关联公司、我们及其关联公司的董事、高级职员、员工和代理人（统称为“**人员**”）免受因以下原因或与以下原因有关而遭受或产生的任何和所有索赔、要求、诉讼、损害、义务、损失、责任、成本、罚款或费用（包括但不限于我们按全额赔偿基础产生的法律费用）：

a. 您使用平台或服务或由此获得的结果；

b. 您违反本协议；

c. 您对任何人员的财产造成的任何损坏或伤害；

d. 您对任何个人和/或其财产造成的任何损坏或伤害；以及

e. 您侵犯任何第三方权利（包括任何知识产权、财产权或隐私权）。

4. 您进一步承认并同意，任何人员都有权依赖并执行第 10.6 条中的赔偿条款，就像这些人员是本协议的一方一样。

5. 您在此承认并同意，本条款中的免责声明、责任限制和赔偿，以及本协议其他条款中的风险分配，是 SiliconFlow 提供平台和/或服务的重要条件，若无这些条款，SiliconFlow 将不会提供平台和/或服务或签订本协议。

## 11. **知识产权**

11.1 所有权

a. 您承认并同意，SiliconFlow 及其第三方许可方拥有以下所有权利、所有权和利益（包括但不限于知识产权）：

* i. 平台、服务和文档；
* ii. 任何商标、服务标志、商号、域名、网站名称、其他显著品牌特征或特定描述，这些将使第三方能够识别 SiliconFlow 和/或其关联公司（统称为“**SiliconFlow 专有标记**”）；
* iii. 所有从这些资源开发或衍生出的更新、衍生作品和修改，包括但不限于任何软件、源代码和目标代码、算法、数据模型、技术、网页、文本、图片、图像、音频、视频、图表、布局设计和电子文档，或对平台和服务的定制；
* iv. 与 SiliconFlow 提供平台或服务相关的任何无形想法、剩余知识、概念、技术知识和技巧，包括但不限于任何与平台或服务的新功能相关的无形想法、剩余知识、概念、技术知识和技巧，无论是否为您创建；
* v. 与平台和服务相关的任何运营和技术数据（包括但不限于用户账户信息、注册数据、操作记录和服务订单）

> （统称为“**SiliconFlow 知识产权**”）。

b. 您与我们之间，您保留对交互数据中的权利（包括知识产权，如有）的所有权。您可以在遵守以下规定和法律法规的基础上使用大型模型生成的结果：(i) 您对服务的使用和对输出的使用不会转让或侵犯任何知识产权（包括 Silicone Flow 和第三方的知识产权）；(ii) 如果我们自行决定认为您对输出的使用违反法律法规或可能侵犯任何第三方的权利，我们可以在任何时候限制您对输出的使用，并要求您停止使用输出（并删除其任何副本）；(iii) 您不得声称大型语言模型的输出是人类生成的；(iv) 您不得违反模型提供者的任何许可或使用限制。

11.2 除了本协议中明确授予的对 SiliconFlow 知识产权的有限许可和使用权外，SiliconFlow 不授予您任何其他权利，并保留其中的所有权利。

11.3 您不得，也不得允许任何其他人：

a. 除按照本协议的条款和以其他方式被允许外，访问或使用 SiliconFlow 知识产权；

b. 显示、使用、申请注册任何 SiliconFlow 专有标记；

c. 向任何其他人声称您有权显示、使用或以其他方式处置 SiliconFlow 专有标记；

d. 修改、更改、删除或销毁放置在或包含在平台、服务或任何文档中的任何 SiliconFlow 专有标记；

e. 采取任何可能导致平台和/或服务或其任何部分进入公共领域或成为开源软件的行动。

11.4 您进一步承认，您（而非 SiliconFlow）完全负责所有通过平台和/或服务提供的交互数据、输入、输出以及所有内容或其他材料。

## 12. **反馈**

a. 如果您向 SiliconFlow 提出或提供任何想法、建议、推荐、增强、改进或其他反馈（统称为“反馈”），则您将所有权利、所有权和利益，包括所有版权、专利、商业外观权利和其他知识产权，转让给 SiliconFlow。

b. SiliconFlow 有权以任何方式和出于任何目的使用和披露此类反馈中包含的任何想法、技术知识、概念、技巧或其他知识产权，而无需向您支付报酬、补偿或注明出处，但上述规定不排除 SiliconFlow 使用此类反馈的义务。

c. 此外，通过在平台上发布评论或评价，您同意授予 SiliconFlow 使用提交的名称、与所述评价、评论或其他内容相关的权利。您不得使用虚假的电子邮件地址，冒充他人或以其他方式欺骗或误导 SiliconFlow 或第三方关于任何提交的来源。

d. 您承认 SiliconFlow 没有义务发布您提交的任何材料，并且可以在任何时候编辑或删除之前提交的材料。

## 13. **协议期限和终止**

13.1 本协议自您接受本协议之日起生效（如前文所述），并在您访问或使用平台和服务期间保持完全效力，除非根据本协议提前终止（“期限”）。为避免疑义，您在此承认并同意，本协议自以下较早日期起生效：(a) 您首次访问平台或服务的日期，或 (b) 您接受本协议的日期。

13.2 在本协议终止时：

1. 授予您的所有权利和许可将终止，您应立即停止使用平台和服务；

2. 您对平台和服务的访问可能会被禁止；

3. 您的账户及相关信息、文件和内容（包括您的交互数据）可能会被 SiliconFlow 自行决定从数据库中删除。您承认并同意，SiliconFlow 对删除您的账户或交互数据不承担任何责任；以及

4. 如适用，您应迅速支付截至终止生效日期应付给 SiliconFlow 的所有款项。

13.3 本协议中任何明确规定或暗示在本协议终止后继续有效的条款应继续完全有效，包括但不限于**第 1 条**（定义）、**第 3 条**（用户义务和限制）、**第 10 条**（免责声明、责任限制和赔偿）、**第 11 条**（知识产权）、**第 13 条**（协议期限和终止）、**第 14 条**（适用法律和争议解决）和**第 15 条**（一般条款）。

## 14. **适用法律和争议解决**

1. 本协议受新加坡共和国法律管辖并根据其法律解释。

2. 因本协议产生或与本协议相关的任何争议，包括任何关于本协议的存在、有效性或终止的问题，应提交至新加坡国际仲裁中心（“**SIAC**”）在新加坡进行仲裁，并根据新加坡国际仲裁中心（“**SIAC 规则**”）当时有效的仲裁规则进行，这些规则被视为通过参考纳入本条款。仲裁地点为新加坡。仲裁庭由一名仲裁员组成。仲裁语言为英语。

## 15. **一般条款**

15.1 **无第三方受益人**。任何非本协议一方的第三方（无论其是否在本协议中被命名、提及或以其他方式识别，或是否属于本协议中此类被命名、提及或识别的人员类别）均无权执行或依赖本协议的任何条款。

15.2 **合伙关系**。您和我们均不会因本协议而被视为彼此的合伙人或代理人，亦不得将本协议的任何内容解释为创建了合伙关系、联合协会或信托。双方同意，各自仅对本协议项下的义务负责，任何一方均无权代表另一方或使另一方受约束于任何其他个人。

15.3 **通知**。若 SiliconFlow 要求您提供电子邮件地址，您有责任向 SiliconFlow 提供您最新的电子邮件地址。若您向 SiliconFlow 提供的最后一个电子邮件地址无效，或因任何原因无法将协议要求或允许的通知送达您，SiliconFlow 发送包含此类通知的电子邮件的行为仍构成有效通知。所有发送给您的通知或其他通信将在以下时间被视为已收到：(a) 若通过我们选择的任何印刷或电子媒体发送，则为发布或播出之日；(b) 若通过邮寄或留在您最后一个已知地址，则为邮寄之日后的第二天或留在您最后一个已知地址之日；或 (c) 若通过电子邮件发送，则为我们发送电子邮件的时间。您只能通过书面形式将通知发送到我们指定的地址或电子邮件地址。我们仅在收到此类通知时才被视为已收到。虽然我们会尽力尽快回复客户通知，但不能保证总是能以一致的速度回复。您同意以电子方式接收我们的通信。您同意，我们以电子方式提供的所有协议、通知、披露和其他通信均满足此类通信具有书面形式的任何法律要求。您还放弃任何法律要求下在任何管辖区要求原件（非电子）签名或交付或保留非电子记录的权利。

15.4 **无不利解释规则**。您承认并同意，在访问或使用平台和服务之前，您有机会寻求或已寻求独立法律顾问的建议，并已阅读并理解本协议的所有条款和条件及其法律效力。本协议不应因 SiliconFlow 起草其条款而对其不利解释，任何文件应对其起草方不利解释的规则不适用于本协议。

15.5 **不放弃**。我们未能行使或延迟行使本协议项下的任何权利或补救措施，不构成对该权利或补救措施的放弃，任何单次或部分行使任何权利或补救措施也不妨碍任何其他或进一步的行使，或行使任何其他权利或补救措施。

15.6 **累积的权利和补救措施**。除非本协议另有规定，本协议的条款以及我们在本协议项下的权利和补救措施是累积的，不影响我们在法律或衡平法下的任何其他权利或补救措施，我们行使本协议、法律或衡平法下的任何一项权利或补救措施，不得（除非本协议或法律、衡平法另有明确规定）妨碍或阻止我们行使任何其他此类权利或补救措施。

15.7 **转让**

a. 本协议对我们和您以及我们和您的继任者和被许可受让人具有约束力，并为我们和您的利益而订立。未经我们事先书面同意，您不得转让或转移本协议项下的任何权利、利益或义务。任何转让均不得解除或免除您在本协议项下的任何义务或责任，尽管受让人可能自愿承担此类义务和责任。

b. 我们有权自行决定将与平台、服务以及我们履行本协议项下义务相关的任何职能的履行进行分包或委托，并保留在我们认为适当的条款下使用任何服务提供商、分包商和/或代理人的权利。

15.8 \*\*可分割性。\*\*如果具有管辖权的法院发现本协议的任何条款无效或不可执行，该条款将被修改以尽可能接近实现双方的意图，本协议的其余部分仍保持完全效力。

15.9 **语言**。本协议仅以英文订立，任何其他语言的翻译版本均不对双方具有约束力。


# 更新公告
Source: https://docs.siliconflow.com/cn/release-notes/overview



<Update label="2025.05.28" description="">
  ### 模型下线通知

  为了进一步优化资源配置，提供更先进和优质的技术服务，平台将于 2025 年 6 月 5 日 对下列模型进行下线处理：

  deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B

  若您正在使用上述模型，建议您尽快切换到其他模型，以免服务受到影响。
</Update>


# 在 DB-GPT 中使用
Source: https://docs.siliconflow.com/cn/usercases/use-siliconcloud-in-DB-GPT



## 1.关于 DB-GPT

[DB-GPT](https://github.com/eosphoros-ai/DB-GPT) **是一个开源的 AI 原生数据应用开发框架 (AI Native Data App Development framework with AWEL(Agentic Workflow Expression Language) and Agents)。**

目的是构建大模型领域的基础设施，通过开发多模型管理 (SMMF)、Text2SQL 效果优化、RAG 框架以及优化、Multi-Agents 框架协作、AWEL(智能体工作流编排) 等多种技术能力，让围绕数据库构建大模型应用更简单，更方便。

## 2.获取 API Key

2.1 打开 [SiliconCloud 官网](https://cloud.siliconflow.com/) 并注册账号（如果注册过，直接登录即可）。

2.2 完成注册后，打开[API 密钥](https://cloud.siliconflow.com/account/ak) ，创建新的 API Key，点击密钥进行复制，以备后续使用。

## 3.部署 DB-GPT

### 3.1 克隆 DB-GPT 源码

```bash
git clone https://github.com/eosphoros-ai/DB-GPT.git
```

### 3.2 创建虚拟环境并安装依赖

```bash
# cd 到 DB-GPT 源码根目录
cd DB-GPT

# DB-GPT 要求python >= 3.10
conda create -n dbgpt_env python=3.10
conda activate dbgpt_env

# 这里选择代理模型类依赖安装
pip install -e ".[proxy]"
```

### 3.3 配置基础的环境变量

```bash
# 复制模板 env 文件为 .env
cp .env.template .env
```

### 3.4 修改环境变量文件`.env`，配置 SiliconCloud 模型

```bash
#  使用 SiliconCloud 的代理模型
LLM_MODEL=siliconflow_proxyllm
# 配置具体使用的模型名称
SILICONFLOW_MODEL_VERSION=Qwen/Qwen2.5-Coder-32B-Instruct
SILICONFLOW_API_BASE=https://api.ap.siliconflow.com/v1
# 记得填写您在步骤2中获取的 API Key
SILICONFLOW_API_KEY={your-siliconflow-api-key}

# 配置使用 SiliconCloud 的 Embedding 模型
EMBEDDING_MODEL=proxy_http_openapi
PROXY_HTTP_OPENAPI_PROXY_SERVER_URL=https://api.ap.siliconflow.com/v1/embeddings
# 记得填写您在步骤2中获取的 API Key
PROXY_HTTP_OPENAPI_PROXY_API_KEY={your-siliconflow-api-key}
# 配置具体的 Embedding 模型名称
PROXY_HTTP_OPENAPI_PROXY_BACKEND=BAAI/bge-large-zh-v1.5


# 配置使用 SiliconCloud 的 rerank 模型
RERANK_MODEL=rerank_proxy_siliconflow
RERANK_PROXY_SILICONFLOW_PROXY_SERVER_URL=https://api.ap.siliconflow.com/v1/rerank
# 记得填写您在步骤2中获取的 API Key
RERANK_PROXY_SILICONFLOW_PROXY_API_KEY={your-siliconflow-api-key}
# 配置具体的 rerank 模型名称
RERANK_PROXY_SILICONFLOW_PROXY_BACKEND=BAAI/bge-reranker-v2-m3
```

注意，上述的 `SILICONFLOW_API_KEY`、 `PROXY_HTTP_OPENAPI_PROXY_SERVER_URL` 和`RERANK_PROXY_SILICONFLOW_PROXY_API_KEY`环境变量是您在步骤 2 中获取的 SiliconCloud 的 Api Key。语言模型（`SILICONFLOW_MODEL_VERSION`)、Embedding 模型（`PROXY_HTTP_OPENAPI_PROXY_BACKEND`）和 rerank 模型 (`RERANK_PROXY_SILICONFLOW_PROXY_BACKEND`) 可以从 [获取用户模型列表 - SiliconFlow](https://docs.siliconflow.com/api-reference/models/get-model-list)  中获取。

### 3.5 启动 DB-GPT 服务

```bash
dbgpt start webserver --port 5670
```

在浏览器打开地址 [http://127.0.0.1:5670/](http://127.0.0.1:5670/) 即可访问部署好的 DB-GPT

## 4.通过 DB-GPT Python SDK 使用 SiliconCloud 的模型

### 4.1  安装 DB-GPT Python 包

```bash
pip install "dbgpt>=0.6.3rc2" openai requests numpy
```

为了后续验证，额外安装相关依赖包。

### 4.2. 使用 SiliconCloud 的大语言模型

```python
import asyncio
import os
from dbgpt.core import ModelRequest
from dbgpt.model.proxy import SiliconFlowLLMClient

model = "Qwen/Qwen2.5-Coder-32B-Instruct"
client = SiliconFlowLLMClient(
    api_key=os.getenv("SILICONFLOW_API_KEY"),
    model_alias=model
)

res = asyncio.run(
    client.generate(
        ModelRequest(
            model=model,
            messages=[
                {"role": "system", "content": "你是一个乐于助人的 AI 助手。"},
                {"role": "human", "content": "你好"},
            ]
        )
    )
)
print(res)
```

### 4.3 使用 SiliconCloud 的 Embedding 模型

```python
import os
from dbgpt.rag.embedding import OpenAPIEmbeddings

openai_embeddings = OpenAPIEmbeddings(
    api_url="https://api.ap.siliconflow.com/v1/embeddings",
    api_key=os.getenv("SILICONFLOW_API_KEY"),
    model_name="BAAI/bge-large-zh-v1.5",
)

texts = ["Hello, world!", "How are you?"]
res = openai_embeddings.embed_documents(texts)
print(res)
```

### 4.4 使用 SiliconCloud 的 rerank 模型

```python
import os
from dbgpt.rag.embedding import SiliconFlowRerankEmbeddings

embedding = SiliconFlowRerankEmbeddings(
    api_key=os.getenv("SILICONFLOW_API_KEY"),
    model_name="BAAI/bge-reranker-v2-m3",
)
res = embedding.predict("Apple", candidates=["苹果", "香蕉", "水果", "蔬菜"])
print(res)
```

## 5. 上手指南

以数据对话案例为例，数据对话能力是通过自然语言与数据进行对话，目前主要是结构化与半结构化数据的对话，可以辅助做数据分析与洞察。以下为具体操作流程：

### 1. 添加数据源

首先选择左侧数据源添加，添加数据库，目前 DB-GPT 支持多种数据库类型。选择对应的数据库类型添加即可。这里我们选择的是 MySQL 作为演示，演示的测试数据参见测试样例（[https://github.com/eosphoros-ai/DB-GPT/tree/main/docker/examples/sqls）。](https://github.com/eosphoros-ai/DB-GPT/tree/main/docker/examples/sqls）。)

### 2. 选择对话类型

选择 ChatData 对话类型。

### 3. 开始数据对话

注意：在对话时，选择对应的模型与数据库。同时 DB-GPT 也提供了预览模式与编辑模式。


# 在 Chatbox 中使用
Source: https://docs.siliconflow.com/cn/usercases/use-siliconcloud-in-chatbox



## 1 关于 Chatbox

Chatbox 是一个流行的大语言模型的全平台聊天客户端，特点是功能强大、安装简单。你可以用它接入各种大语言模型，然后在任何设备（电脑、手机、网页）上和 AI 聊天。

Chatbox 不仅提供简单好用的 AI 聊天功能，还提供了一系列强大功能：

* Artifact 预览：在 Chatbox 中你可以预览 AI 生成代码的实际效果，比如让 AI 帮你做一个网页、贪吃蛇游戏，然后在 Chatbox 中直接运行。
* 图表制作：让 AI 绘制思维导图、流程图、统计图表
* 文档理解和图形视觉：可以向 AI 发送文档或者图片
  -网页解析与识别：可以向 AI 发送链接，讨论网页内容等

## 2 安装使用 Chatbox

浏览器访问 [Chatbox 官网](https://chatboxai.app/)下载安装包。

Chatbox 支持所有的主流操作系统，包括 Windows、MacOS 和 Linux，手机系统支持 iOS 和 Android。下载安装包后，在系统中直接安装即可。或者也可以访问和使用 Chatbox 的网页版本。

## 3 在 Chatbox 中使用 SiliconCloud 模型

### 3.1 配置 SiliconCloud API 密钥

访问[API 密钥](https://cloud.siliconflow.com/account/ak)新建或复制已有密钥。

### 3.2 在 Chatbox 中配置

#### 3.2.1 打开 Chatbox，进入设置

#### 3.2.2 创建自定义模型提供方

先点击“模型提供方”切换按钮，在弹出菜单的底部点击“添加自定义提供方”

#### 3.2.3 配置 SiliconCloud 的接入信息

请在打开的表单中填写 SiliconCloud 的接入配置即可：

* 名称（比如可以是 SiliconCloud，方面后续使用区分)
* API 域名填写：[https://api.ap.siliconflow.com/](https://api.ap.siliconflow.com/)
* API 路径填写：/v1/chat/completions
* API 密钥：填写在 SiliconCloud 后台新建的 API 密钥
* 在模型输入框添加你需要使用的模型（比如 Qwen/Qwen2.5-7B-Instruct），你可以在[模型广场](https://cloud.siliconflow.com/models)找到 SiliconCloud 所有模型选项
* 点击保存，即可开始聊天

### 3.2.4 开始聊天

按照上面步骤，基本上已经配置成功了，简单聊天测试一下。

### 3.3 使用技巧

在结尾这里在顺带介绍一些 Chatbox 的使用技巧。

#### 3.3.1 利用 Chatbox 的图表能力，在聊天中生成可视化图表

Chatbox 的“做图表”助手会生成各种图表，在聊天中可以更方便地让你理解一些数据。

注意：为了更好的效果，需要选择更聪明更强大的模型。模型能力将直接决定图表的效果。

#### 3.3.2 利用 Chatbox 的 Artifact 预览功能，查看 AI 生成代码的运行效果

Chatbox 的 Artifact 预览功能，则可以让你直接预览 AI 生成前端代码的实际运行效果。

注意：为了更好的效果，需要选择更聪明更强大的模型。模型能力将直接决定生成代码的效果。

除了这些技巧外，在 Chatbox 简单易用的外表下，还隐藏着非常多强大的功能，有很多值得探索的地方。


# 在 ChatHub 中使用
Source: https://docs.siliconflow.com/cn/usercases/use-siliconcloud-in-chathub



## 关于 ChatHub

[ChatHub](https://chathub.gg/zh) 是一个流行的大语言模型聚合插件，特点是可以同时和多个模型聊天，方便对比回答。ChatHub 在全球拥有数十万活跃用户。

## 安装 ChatHub

浏览器打开 [ChatHub 官网](https://chathub.gg/zh)，点击“新增至 Chrome”按钮安装 ChatHub 浏览器插件：

安装后，将自动打开 ChatHub 设置页面。

## 在 ChatHub 中使用 SiliconCloud 模型

1、在 ChatHub 设置中找到“自定义机器人”模块，点击“添加”按钮

2、在弹窗中，依次：

1. 输入机器人名称
2. 选择 SiliconFlow 作为提供方
3. 输入 SiliconFlow 密钥
4. 填写 SiliconFlow 支持的任何模型

3、点击“确认”后模型即配置成功

4、开始聊天

## 在 ChatHub 中进行多模型对比

你可以重复上面的步骤在 ChatHub 添加其他模型，然后你就可以使用 ChatHub 的 All-in-One 功能同时和多个模型聊天（最多可以同时和 6 个模型对话）：

除了核心的对比功能外，ChatHub 还有提示词库、代码预览等强大的功能，可以在 [ChatHub 官方文档](https://doc.chathub.gg/introduction)了解更多。


# 在 Cline 中使用
Source: https://docs.siliconflow.com/cn/usercases/use-siliconcloud-in-cline



## 1. 安装 Cline

[安装地址](https://marketplace.visualstudio.com/items?itemName=saoudrizwan.claude-dev)

## 2. 打开 cline

在 VSCode 中，通过 Ctrl/Command+Shift+P 打开命令工具，在新 tab 中打开 Cline 进行配置

## 3. 在新窗口中进行配置

1. API Provider：选择“OpenAI Compatible”
2. Base Url：[https://api.ap.siliconflow.com/v1](https://api.ap.siliconflow.com/v1)
3. API Key：从 [https://cloud.siliconflow.com/account/ak](https://cloud.siliconflow.com/account/ak) 中获取
4. Model ID：从 [https://cloud.siliconflow.com/models](https://cloud.siliconflow.com/models) 中获取

完成以上操作，即可开始在 Cline 中使用 SiliconCloud。


# Deep Research Web UI
Source: https://docs.siliconflow.com/cn/usercases/use-siliconcloud-in-deep-research-web-ui



## 1. 介绍

Deep Research Web UI 是一个由人工智能驱动的研究助手，通过结合搜索引擎、网络抓取和大语言模型，可以让 AI 根据某个问题自己搜索资料并且不断深挖，最后输出一份研究报告。

本项目的特性：

* 💰 **低成本**：可以用很低的成本实现类似 ChatGPT、Perplexity、秘塔等产品的“深度研究”效果
* 🚀 **隐私安全**：所有配置和 API 请求均在浏览器端完成，并且可以自部署
* 🕙 **实时反馈**：流式传输 AI 响应并在界面实时展示
* 🌳 **搜索可视化**：使用树状结构展示研究过程，支持使用英文搜索词
* 📄 **支持导出 PDF**：将最终研究报告导出为 Markdown 和 PDF 格式
* 🤖 **多模型支持**：底层使用纯提示词而非结构化输出等新特性，兼容更多大模型供应商

项目开源地址： [GitHub](https://github.com/AnotiaWang/deep-research-web-ui)

## 2. 如何使用

打开 [Deep Research Web UI 官网](https://deep-research.ataw.top)，点击右上角的“⚙️”按钮打开设置弹窗。

<Frame>
  <img width="500" src="https://mintlify.s3.us-west-1.amazonaws.com/siliconflowcom/images/usercases/deep-research/deep-research-showcase-1.webp" />
</Frame>

### 2.1 配置 AI 大模型服务

1. 在硅基流动官网注册或者登录一个账号。
2. 在 [API 密钥](https://cloud.siliconflow.cn/account/ak)中生成一个新的 API key，然后复制一下。
3. 回到 Deep Research 网页，在设置的 AI 服务部分，选择“SiliconFlow 硅基流动”，在“API 密钥”一栏里粘贴刚才生成的 API key。

<Frame>
  <img width="500" src="https://mintlify.s3.us-west-1.amazonaws.com/siliconflowcom/images/usercases/deep-research/deep-research-showcase-2.webp" />
</Frame>

4. 在“模型名称”一栏，点击右侧的下拉按钮（也可以在输入框里输入模型名称来筛选），选择想要使用的模型。

<Frame>
  <img width="500" src="https://mintlify.s3.us-west-1.amazonaws.com/siliconflowcom/images/usercases/deep-research/deep-research-showcase-3.webp" />
</Frame>

5. （可选）设置上下文长度：如果要做大规模的研究，建议配置“上下文长度”选项，不要超过所选模型的最大上下文长度，避免请求失败。

### 2.2 配置联网搜索模型

目前支持 Tavily 和 Firecrawl，后续会增加支持更多搜索服务。这里我们选择 Tavily，因为它提供了每月 1000 次的免费搜索，足够大部分场景使用。

1. 在 [Tavily 官网](https://app.tavily.com/home)注册一个账号。然后在控制台里新建一个 API key 并复制。
   * Key Name 可以填写 Deep Research。
   * Key Type 根据你的使用情况决定，如果是轻度使用，可以选择“Development”；重度使用则选择“Production”，支持更高的请求频率。
   * 注意保管好 API key 不要泄露。

<Frame>
  <img width="500" src="https://mintlify.s3.us-west-1.amazonaws.com/siliconflowcom/images/usercases/deep-research/deep-research-showcase-4.webp" />
</Frame>

2. 回到 Deep Research 网页，在设置的“联网搜索服务”部分，选择 “Tavily”；在“API 密钥”一栏填写刚才生成的 API key。
3. （可选）设置搜索时使用的语言。AI 模型默认会使用你网页的当前语言来搜索和回复，不过如果你想用英文搜索词来查找更高质量的资料，可以把“使用语言”设置成 English。

这样就设置完毕，可以开始使用了！

### 3. 开始使用

本项目在每一步都做了说明，力求降低使用门槛。可以用它来查找第一手资料、了解自己感兴趣的话题、查找新闻并汇总等等。例如，查找一下 NVIDIA RTX 50 系列显卡的信息：

<Frame>
  <img width="500" src="https://mintlify.s3.us-west-1.amazonaws.com/siliconflowcom/images/usercases/deep-research/deep-research-showcase-5.webp" />
</Frame>

<Frame>
  <img width="500" src="https://mintlify.s3.us-west-1.amazonaws.com/siliconflowcom/images/usercases/deep-research/deep-research-showcase-6.webp" />
</Frame>

本项目正在活跃更新中，如果遇到问题可以前往 [GitHub 仓库](https://github.com/AnotiaWang/deep-research-web-ui)反馈。


# 在 Dify 中使用
Source: https://docs.siliconflow.com/cn/usercases/use-siliconcloud-in-dify

结合 SiliconCloud 模型多，速度快的优势，在 Dify 中快速实现工作流/Agent 

## 1. 获取 API Key

1. 打开 SiliconCloud [官网](https://cloud.siliconflow.com/) 并注册账号（如果注册过，直接登录即可）。
2. 完成注册后，打开[API 密钥](https://cloud.siliconflow.com/account/ak) ，创建新的 API Key，点击密钥进行复制，以备后续使用。

## 2. 在 Dify 中使用 SiliconCloud 语言模型系列

### 2.1 调用 Dify 中内置的 SiliconCloud 模型的 API

1. 打开 SiliconCloud 官网 并注册账号（如果注册过，直接登录即可）。完成注册后，打开 API 密钥，创建新的 API Key，点击密钥进行复制，以备后续使用。
2. 在 Dify 首页右上角选择“设置”，选择左上角“模型供应商”。
3. 找到“SiliconCloud”，粘贴先前在 SiliconCloud 平台复制的 API Key，然后点击“保存”按钮。
4. 校验成功后可以在模型提供商的顶部区域看到 SiliconCloud 提供的模型，并在应用中使用 SiliconCloud 模型。

### 2.2 使用目前不在 Dify 源代码中的 SiliconCloud 模型

1. 打开 Dify 的“Settings”进行设置。
2. 选择导航栏“Model Provider”，添加兼容 OpenAI 接口的模型服务平台。
3. 在其中设置对应的 SiliconCloud 对应的 Model Name、API Key、API 端点。

* **Model Name:** 从[model-list](/api-reference/models/get-model-list) 文档中选择
* \*\*API Key:\*\*从 [https://cloud.siliconflow.com/account/ak](https://cloud.siliconflow.com/account/ak) 中获取，请注意，如果您需要使用海外模型，请先进行实名认证证
* **API 端点 URL：** [https://api.ap.siliconflow.com/v1](https://api.ap.siliconflow.com/v1)

4. 设置完成后，可以在模型列表中看到上述新增的模型。

## 3. 在 Dify 中使用 SiliconCloud 生图模型系列

参考[在 Dify 中使用 SiliconCloud 生图模型系列](hhttps://docs.dify.ai/zh-hans/guides/tools/tool-configuration/siliconflow)


# 在 MindSearch 中使用
Source: https://docs.siliconflow.com/cn/usercases/use-siliconcloud-in-mindsearch



## 1. 获取 API Key

1. 打开 SiliconCloud [官网](https://cloud.siliconflow.com/) 并注册账号（如果注册过，直接登录即可）。
2. 完成注册后，打开[API 密钥](https://cloud.siliconflow.com/account/ak) ，创建新的 API Key，点击密钥进行复制，以备后续使用。

## 2. 部署 MindSearch

1. 复制 MindSearch 到本地并安装相关依赖后（参考 [https://github.com/InternLM/MindSearch/blob/main/README.md）](https://github.com/InternLM/MindSearch/blob/main/README.md）) ，

2. 修改：
   `/path/to/MindSearch/mindsearch/models.py`

3. 加上调用 SiliconFlow API 的相关配置。配置如下：

```
internlm_silicon = dict(type=GPTAPI,
                        model_type='internlm/internlm2_5-7b-chat',
                        key=os.environ.get('SILICON_API_KEY', 'YOUR SILICON API KEY'),
                        openai_api_base='https://api.ap.siliconflow.com/v1/chat/completions',
                        meta_template=[
                            dict(role='system', api_role='system'),
                            dict(role='user', api_role='user'),
                            dict(role='assistant', api_role='assistant'),
                            dict(role='environment', api_role='system')
                        ],
                        top_p=0.8,
                        top_k=1,
                        temperature=0,
                        max_new_tokens=8192,
                        repetition_penalty=1.02,
                        stop_words=['<|im_end|>'])
```

加入这段配置后，可以执行相关指令来启动 MindSearch。

4. 启动后端：

```
# 指定 SiliconFlow 的 API Key
export SILICON_API_KEY=上面流程中复制的密钥
# 启动
python -m mindsearch.app --lang en --model_format internlm_silicon --search_engine DuckDuckGoSearch
```

5. 启动前端。这里以 gradio 前端为例，其他前端启动可以参考 MindSearch 的 README：
   `python frontend/mindsearch_gradio.py`

## 3. 上传到 HuggingFace Space

我们也可以选择部署到 HuggingFace 的 Space 当中。

1. 在 [https://huggingface.co/new-space](https://huggingface.co/new-space) 创建一个新的 Space，
   配置为：
   Gradio
   Template:Blank
   Hardware:CPU basic·2 vCPU·16GB·FREE

2. 创建成功后，进入" Settings "设置 API Key。

3. 把第二步中的 MindSearch 目录、requirements.txt 和一个 app.py 一并上传。

app.py 详细内容请参考：[https://huggingface.co/spaces/SmartFlowAI/MindSearch\_X\_SiliconFlow/blob/main/app.py](https://huggingface.co/spaces/SmartFlowAI/MindSearch_X_SiliconFlow/blob/main/app.py)


# 在 Sider 中使用
Source: https://docs.siliconflow.com/cn/usercases/use-siliconcloud-in-sider



作为 2023 年“Chrome 编辑推荐扩展”，Sider 获得了超过 5 万条“五星好评”，并拥有超过 600 万活跃用户。Sider 浏览器扩展主要解决以下问题：

* Sider（ChatGPT 侧边栏）是您贴心的 AI 助手，可以在浏览任何网站时使用它。

<Note>
  1. 开发者可以访问 [Sider 官方网站](https://sider.ai/en/) 使用 Sider 应用。
  2. Sider 提供了一种兼容 OpenAI API 模型的注册方式，以满足软件开发者的需求，使使用所需模型更加便捷。
  3. 作为集成顶级 AI 模型的一站式云服务平台，SiliconCloud 致力于为开发者提供更快、更便宜、更全面、更流畅的模型 API。
</Note>

那么如何在 Sider 中使用 SiliconCloud？

## 1. 获取 API Key

1. 打开 SiliconCloud [官网](https://cloud.siliconflow.com/) 并注册账号（如果已经注册，直接登录即可）。
2. 注册完成后，前往 [API 密钥](https://cloud.siliconflow.com/account/ak)，创建新的 API Key，并复制密钥以供后续使用。

## 2. 在 Sider 中使用 SiliconCloud 语言模型

1. 打开 Sider 设置。
2. 使用 OpenAI API Key 模式。
3. 输入从 SiliconCloud 获取的 API Key。
4. 输入对应的 SiliconCloud API 端点地址。
5. 输入来自 SiliconCloud 的模型名称。
6. 在对话框中进行验证以确保其正常工作。


# 生图模型
Source: https://docs.siliconflow.com/cn/userguide/capabilities/images



## 1.生图模型简介

平台提供的生图模型主要有以下两种使用方式：一种是根据 prompt 输入直接生成图像；一种是根据现有图像，加上 prompt 输入，生成图像变体。

* **根据文本提示创建图像**

  在使用文生图的模型时，为了生成更高质量的图像，输入的 prompt（提示词）需要精心设计。以下是一些有助于提高生成图像质量的提示词输入技巧：

  * **具体描述**：尽量详细地描述你想要生成的图像内容。比如，如果你想生成一幅日落的海滩风景，不要仅仅输入“海滩日落”，而是可以尝试输入“一个宁静的海滩上，夕阳西下，天空呈现出橙红色，海浪轻轻拍打着沙滩，远处有一艘小船”。

  * **情感和氛围**：除了描述图像的内容，还可以加入对情感或氛围的描述，比如“温馨的”、“神秘的”、“充满活力的”等，这样可以帮助模型更好地理解你想要的风格。

  * **风格指定**：如果你有特定的艺术风格偏好，比如“印象派”、“超现实主义”等，可以在 prompt 中明确指出，这样生成的图像更有可能符合你的期待。

  * **避免模糊不清的词汇**：尽量避免使用过于抽象或模糊不清的词汇，比如“美”、“好”等，这些词汇对于模型来说难以具体化，可能会导致生成的图像与预期相差较大。

  * **使用否定词**：如果你不希望图像中出现某些元素，可以使用否定词来排除。例如，“生成一幅海滩日落的图片，但不要有船”。

  * **分步骤输入**：对于复杂场景，可以尝试分步骤输入提示词，先生成基础图像，再根据需要调整或添加细节。

  * **尝试不同的描述方式**：有时候，即使描述的是同一个场景，不同的描述方式也会得到不同的结果。可以尝试从不同的角度或使用不同的词汇来描述，看看哪种方式能得到更满意的结果。

  * **利用模型的特定功能**：一些模型可能提供了特定的功能或参数调整选项，比如调整生成图像的分辨率、风格强度等，合理利用这些功能也可以帮助提高生成图像的质量。

通过上述方法，可以有效地提高使用文生图模型时生成图像的质量。不过，由于不同的模型可能有不同的特点和偏好，实际操作中可能还需要根据具体模型的特性和反馈进行适当的调整。

可以参考如下示例：

> A futuristic eco-friendly skyscraper in central Tokyo. The building incorporates lush vertical gardens on every floor, with cascading plants and trees lining glass terraces. Solar panels and wind turbines are integrated into the structure's design, reflecting a sustainable future. The Tokyo Tower is visible in the background, contrasting the modern eco-architecture with traditional city landmarks.

> An elegant snow leopard perched on a cliff in the Himalayan mountains, surrounded by swirling snow. The animal’s fur is intricately detailed with distinctive patterns and a thick winter coat. The scene captures the majesty and isolation of the leopard's habitat, with mist and mountain peaks fading into the background.

* **根据现有图像，生成图像变体**

有部分生图模型支持通过已有图像生成图像变体，这种情况下，仍然需要输入适当的 prompt，才能达到预期的效果，具体 prompt 输入，可以参考上面内容。

## 2.体验地址

可以通过 [图像生成](https://cloud.siliconflow.com/playground/image) 体验生图的功能，也可以通过 [API 文档](https://docs.siliconflow.com/api-reference/images/images-generations)介绍，通过 API 进行调用。。

* **重点参数介绍**

  * **image\_size**：控制参数的图像分辨率，API 请求时候，可以自定义多种分辨率。

  * **num\_inference\_steps**：控制图像生成的步长。

  * **batch\_size**：一次生成图像的个数，默认值是 1，最大值可以设置为 4

  * **negative\_prompt**：这里可以输入图像中不想出现的某些元素，消除一些影响影响因素。

  * **seed**：如果想要每次都生成固定的图片，可以把 seed 设置为固定值。

{/*## 3.生图计费介绍

  平台的生图计费分为两种计费方式：
    - **根据图像大小及图像步长进行计费，单价是 ¥x/M px/Steps，即每M像素每步长是x元。**


        比如想要生成一个`宽1024*高512`、4步长的图像，选择单价是`¥0.0032/M px/Steps`的stabilityai/stable-diffusion-3-5-large-turbo模型，那么生成一张图片的价格就是`(1024x512)/(1024x1024)x4x0.0032=0.0064元`，其中2代表`宽1024*高512`像素的大小是0.5M，生成一张图像的价格跟生成图像的像素大小和价格都有关系。

    - **根据图片张数进行计费，单价是`¥x/Image`，即每张图片的价格是 x 元。**

        比如想要生成一个`宽1024*高512`像素，4 步长的图像，选择单价是`¥0.37/Image`的 black-forest-labs/FLUX.1-pro 模型，那么生成一张图片的价格就是`0.37元`，生成一张图像的价格，跟像素和步长都无关。

  <Note>注意：选择的模型不一样，计费方式可能不同，请用户根据自身需求，选择相应计费方式的模型。</Note>   */}

## 3.支持模型列表

目前已支持的生图模型：

* 文生图系列：
  * black-forest-labs 系列：
    * black-forest-labs/FLUX.1-dev
    * black-forest-labs/FLUX.1-schnell

<Note>注意：支持的生图模型可能发生调整，请在「模型广场」筛选“生图”标签，了解支持的模型列表。</Note>


# 推理模型
Source: https://docs.siliconflow.com/cn/userguide/capabilities/reasoning



## 概述

DeepSeek-R1 是一系列由 deepseek-ai 开发的高级语言模型，旨在通过输出思维链内容（reasoning\_content）来提升最终回答的准确性。目前该接口和 deepseek 接口兼容，在使用该模型时，建议先升级 OpenAI SDK 以支持新参数。

### 支持模型列表：

* THUDM/GLM-Z1-32B-0414
* THUDM/GLM-Z1-9B-0414
* deepseek-ai/DeepSeek-R1
* deepseek-ai/DeepSeek-R1-Distill-Qwen-32B
* deepseek-ai/DeepSeek-R1-Distill-Qwen-14B
* deepseek-ai/DeepSeek-R1-Distill-Qwen-7B
* deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B

## 安装与升级

在使用 DeepSeek-R1 之前，请确保已安装最新版本的 OpenAI SDK。可以通过以下命令进行升级：

```bash
pip3 install -U openai
```

## API 参数

* 输入参数：
  * max\_tokens：回答的最大长度（包含思维链输出），max\_tokens 最大为 16k。

* 返回参数：
  * reasoning\_content：思维链内容，与 content 同级。

  * content：最终回答内容

* 使用建议：
  * 将 temperature 设置在 0.5-0.7 范围内（推荐值为 0.6），以防止无限循环或不连贯的输出。
  * 将 top\_p 的值设置在 0.95。
  * 避免添加系统提示，所有指令应包含在用户提示中。
  * 对于数学问题，建议在提示中包含一个指令，例如：“请逐步推理，并将最终答案写在 \boxed{} 中。”
  * 在评估模型性能时，建议进行多次测试并平均结果。
  * DeepSeek-R1 系列模型在回应某些查询时倾向于绕过思考模式（即输出 "\n\n"），这可能会影响模型的性能。为了确保模型进行充分的推理，建议强制模型在每次输出的开头使用 "\n"。
  {/*
    - 使用特定提示词用于文件上传和网页搜索，以提供更好的用户体验。

        * 对于文件上传，请按照模板创建提示，其中`{file_name}`、`{file_content}` 和 `{question}` 是参数。

        ```bash
        file_template = \
        """[file name]: {file_name}
        [file content begin]
        {file_content}
        [file content end]
        {question}"""
        ```

        * 对于网页搜索，`{search_results}`、`{cur_data}` 和 `{question}`是参数。
        
            * 对于中文查询，使用提示：

        ```bash
        search_answer_zh_template = \
        '''# 以下内容是基于用户发送的消息的搜索结果：
        {search_results}
        在我给你的搜索结果中，每个结果都是[webpage X begin]...[webpage X end]格式的，X 代表每篇文章的数字索引。请在适当的情况下在句子末尾引用上下文。请按照引用编号[citation:X]的格式在答案中对应部分引用上下文。如果一句话源自多个上下文，请列出所有相关的引用编号，例如[citation:3][citation:5]，切记不要将引用集中在最后返回引用编号，而是在答案对应部分列出。
        在回答时，请注意以下几点：
        - 今天是{cur_date}。
        - 并非搜索结果的所有内容都与用户的问题密切相关，你需要结合问题，对搜索结果进行甄别、筛选。
        - 对于列举类的问题（如列举所有航班信息），尽量将答案控制在 10 个要点以内，并告诉用户可以查看搜索来源、获得完整信息。优先提供信息完整、最相关的列举项；如非必要，不要主动告诉用户搜索结果未提供的内容。
        - 对于创作类的问题（如写论文），请务必在正文的段落中引用对应的参考编号，例如[citation:3][citation:5]，不能只在文章末尾引用。你需要解读并概括用户的题目要求，选择合适的格式，充分利用搜索结果并抽取重要信息，生成符合用户要求、极具思想深度、富有创造力与专业性的答案。你的创作篇幅需要尽可能延长，对于每一个要点的论述要推测用户的意图，给出尽可能多角度的回答要点，且务必信息量大、论述详尽。
        - 如果回答很长，请尽量结构化、分段落总结。如果需要分点作答，尽量控制在 5 个点以内，并合并相关的内容。
        - 对于客观类的问答，如果问题的答案非常简短，可以适当补充一到两句相关信息，以丰富内容。
        - 你需要根据用户要求和回答内容选择合适、美观的回答格式，确保可读性强。
        - 你的回答应该综合多个相关网页来回答，不能重复引用一个网页。
        - 除非用户要求，否则你回答的语言需要和用户提问的语言保持一致。

        # 用户消息为：
        {question}'''
        ```

            * 对于英文查询，使用提示：

        ```bash
        search_answer_en_template = \
        '''# The following contents are the search results related to the user's message:
        {search_results}
        In the search results I provide to you, each result is formatted as [webpage X begin]...[webpage X end], where X represents the numerical index of each article. Please cite the context at the end of the relevant sentence when appropriate. Use the citation format [citation:X] in the corresponding part of your answer. If a sentence is derived from multiple contexts, list all relevant citation numbers, such as [citation:3][citation:5]. Be sure not to cluster all citations at the end; instead, include them in the corresponding parts of the answer.
        When responding, please keep the following points in mind:
        - Today is {cur_date}.
        - Not all content in the search results is closely related to the user's question. You need to evaluate and filter the search results based on the question.
        - For listing-type questions (e.g., listing all flight information), try to limit the answer to 10 key points and inform the user that they can refer to the search sources for complete information. Prioritize providing the most complete and relevant items in the list. Avoid mentioning content not provided in the search results unless necessary.
        - For creative tasks (e.g., writing an essay), ensure that references are cited within the body of the text, such as [citation:3][citation:5], rather than only at the end of the text. You need to interpret and summarize the user's requirements, choose an appropriate format, fully utilize the search results, extract key information, and generate an answer that is insightful, creative, and professional. Extend the length of your response as much as possible, addressing each point in detail and from multiple perspectives, ensuring the content is rich and thorough.
        - If the response is lengthy, structure it well and summarize it in paragraphs. If a point-by-point format is needed, try to limit it to 5 points and merge related content.
        - For objective Q&A, if the answer is very brief, you may add one or two related sentences to enrich the content.
        - Choose an appropriate and visually appealing format for your response based on the user's requirements and the content of the answer, ensuring strong readability.
        - Your answer should synthesize information from multiple relevant webpages and avoid repeatedly citing the same webpage.
        - Unless the user requests otherwise, your response should be in the same language as the user's question.

        # The user's message is:
        {question}'''
        ```*/}

## 上下文拼接

在每一轮对话过程中，模型会输出思维链内容（reasoning\_content）和最终回答（content）。在下一轮对话中，之前轮输出的思维链内容不会被拼接到上下文中。

## openai 请求示例

### 流式输出请求

```python
from openai import OpenAI

url = 'https://api.ap.siliconflow.com/v1/'
api_key = 'your api_key'

client = OpenAI(
    base_url=url,
    api_key=api_key
)

# 发送带有流式输出的请求
content = ""
reasoning_content=""
messages = [
    {"role": "user", "content": "奥运会的传奇名将有哪些？"}
]
response = client.chat.completions.create(
    model="deepseek-ai/DeepSeek-R1",
    messages=messages,
    stream=True,  # 启用流式输出
    max_tokens=4096
)
# 逐步接收并处理响应
for chunk in response:
    if chunk.choices[0].delta.content:
        content += chunk.choices[0].delta.content
    if chunk.choices[0].delta.reasoning_content:
        reasoning_content += chunk.choices[0].delta.reasoning_content

# Round 2
messages.append({"role": "assistant", "content": content})
messages.append({'role': 'user', 'content': "继续"})
response = client.chat.completions.create(
    model="deepseek-ai/DeepSeek-R1",
    messages=messages,
    stream=True
)
```

### 非流式输出请求

```python
from openai import OpenAI
url = 'https://api.ap.siliconflow.com/v1/'
api_key = 'your api_key'

client = OpenAI(
    base_url=url,
    api_key=api_key
)

# 发送非流式输出的请求
messages = [
    {"role": "user", "content": "奥运会的传奇名将有哪些？"}
]
response = client.chat.completions.create(
    model="deepseek-ai/DeepSeek-R1",
    messages=messages,
    stream=False, 
    max_tokens=4096
)
content = response.choices[0].message.content
reasoning_content = response.choices[0].message.reasoning_content

# Round 2
messages.append({"role": "assistant", "content": content})
messages.append({'role': 'user', 'content': "继续"})
response = client.chat.completions.create(
    model="deepseek-ai/DeepSeek-R1",
    messages=messages,
    stream=False
)
```

## 注意事项

* API 密钥：请确保使用正确的 API 密钥进行身份验证。
* 流式输出：流式输出适用于需要逐步接收响应的场景，而非流式输出则适用于一次性获取完整响应的场景。

{/* - 上下文管理：在每一轮对话中，模型输出的思维链内容不会被拼接到下一轮对话的上下文中，因此需要手动管理上下文。*/}

## 常见问题

* 如何获取 API 密钥？

  请访问 [SiliconFlow](https://cloud.siliconflow.com/) 注册并获取 API 密钥。
* 如何处理超长文本？

  可以通过调整 max\_tokens 参数来控制输出的长度，但请注意最大长度为 16K。


# 语言模型
Source: https://docs.siliconflow.com/cn/userguide/capabilities/text-generation



## 1. 模型核心能力

### 1.1 基础功能

文本生成：根据上下文生成连贯的自然语言文本，支持多种文体和风格。

语义理解：深入解析用户意图，支持多轮对话管理，确保对话的连贯性和准确性。

知识问答：覆盖广泛的知识领域，包括科学、技术、文化、历史等，提供准确的知识解答。

代码辅助：支持多种主流编程语言（如 Python、Java、C++ 等）的代码生成、解释和调试。

### 1.2 进阶能力

长文本处理：支持 4k 至 64k Tokens 的上下文窗口，适用于长篇文档生成和复杂对话场景。

指令跟随：精确理解复杂任务指令，如“用 Markdown 表格对比 A/B 方案”。

风格控制：通过系统提示词调整输出风格，支持学术、口语、诗歌等多种风格。

多模态支持：除了文本生成，还支持图像描述、语音转文字等多模态任务。

## 2. 接口调用规范

### 2.1 基础请求结构

您可以通过 OpenAI SDK 进行端到端接口请求。

<AccordionGroup>
  <Accordion title="生成对话（点击查看详情）">
    ```python
        from openai import OpenAI  
        client = OpenAI(api_key="YOUR_KEY", base_url="https://api.ap.siliconflow.com/v1")  

        response = client.chat.completions.create(  
            model="deepseek-ai/DeepSeek-V3",  
            messages=[  
                {"role": "system", "content": "You are a helpful assistant."},  
                {"role": "user", "content": "Write a haiku about recursion in programming."}  
            ],  
            temperature=0.7,  
            max_tokens=1024,
            stream=True
        )  
        # 逐步接收并处理响应
        for chunk in response:
            print(chunk.choices[0].delta.content)

    ```
  </Accordion>

  <Accordion title="分析一幅图像（点击查看详情）">
    ```python
    from openai import OpenAI

    client = OpenAI(api_key="YOUR_KEY", base_url="https://api.ap.siliconflow.com/v1")

    response = client.chat.completions.create(
        model="deepseek-ai/deepseek-vl2",
        messages=[
            {
                "role": "user",
                 "content": [
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": "https://sf-maas.s3.us-east-1.amazonaws.com/images/recDq23epr.png",
                            },
                        },
                         {
                             "type": "text",
                             "text": "What's in this image?"
                         }
                    ],
            }
        ],
        temperature=0.7,
        max_tokens=1024,
        stream=True
    )
    # 逐步接收并处理响应
    for chunk in response:
        print(chunk.choices[0].delta.content)
    ```
  </Accordion>

  <Accordion title="生成 JSON 数据（点击查看详情）">
    ```python
    import json  
    from openai import OpenAI

    client = OpenAI(
        api_key="您的 API KEY", # 从 https://cloud.siliconflow.com/account/ak 获取
        base_url="https://api.ap.siliconflow.com/v1"
    )

    response = client.chat.completions.create(
            model="deepseek-ai/DeepSeek-V2.5",
            messages=[
                {"role": "system", "content": "You are a helpful assistant designed to output JSON."},
                {"role": "user", "content": "? 2020 年世界奥运会乒乓球男子和女子单打冠军分别是谁？"
                 "Please respond in the format {\"男子冠军\": ..., \"女子冠军\": ...}"}
            ],
            response_format={"type": "json_object"}
        )

    print(response.choices[0].message.content)
    ```
  </Accordion>
</AccordionGroup>

### 2.2 消息体结构说明

| 消息类型      | 功能描述                            | 示例内容                 |
| --------- | ------------------------------- | -------------------- |
| system    | 模型指令，设定 AI 角色，描述模型应一般如何行为和响应    | 例如："你是有 10 年经验的儿科医生" |
| user      | 用户输入，将最终用户的消息传递给模型              | 例如："幼儿持续低烧应如何处理？"    |
| assistant | 模型生成的历史回复，为模型提供示例，说明它应该如何回应当前请求 | 例如："建议先测量体温..."      |

你想让模型遵循分层指令时，消息角色可以帮助你获得更好的输出。但它们并不是确定性的，所以使用的最佳方式是尝试不同的方法，看看哪种方法能给你带来好的结果。

## 3. 模型系列选型指南

可以进入 [模型广场](https://cloud.siliconflow.com/models)，根据左侧的筛选功能，筛选支持不同功能的语言模型，根据模型的介绍，了解模型具体的价格、模型参数大小、模型上下文支持的最大长度及模型价格等内容。

支持在 [Playground](https://cloud.siliconflow.com/playground/chat)进行体验（Playground 只进行模型体验，暂时没有历史记录功能，如果您想要保存历史的回话记录内容，请自己保存会话内容），想要了解更多使用方式，可以参考考 [API 文档](https://docs.siliconflow.com/cn/api-reference/chat-completions/chat-completions)

## 4. 核心参数详解

### 4.1 创造性控制

```bash
# 温度参数（0.0~2.0）   
temperature=0.5  # 平衡创造性与可靠性  

# 核采样（top_p）   
top_p=0.9  # 仅考虑概率累积 90%的词集  
```

### 4.2 输出限制

```json
max_tokens=1000  # 单词请求最大生成长度  
stop=["\n##", "<|end|>"]  # 终止序列，在返回中遇到数组中对应的字符串，就会停止输出 
frequency_penalty=0.5  # 抑制重复用词（-2.0~2.0）  
stream=true # 控制输出是否是流式输出，对于一些输出内容比较多的模型，建议设置为流失，防止输出过长，导致输出超时
```

### 4.3 语言模型场景问题汇总

**1. 模型输出乱码**

目前看到部分模型在不设置参数的情况下，容易出现乱码，遇到上述情况，可以尝试设置`temperature`，`top_k`，`top_p`，`frequency_penalty`这些参数。

对应的 payload 修改为如下形式，不同语言酌情调整

```python
    payload = {
        "model": "Qwen/Qwen2.5-Math-72B-Instruct",
        "messages": [
            {
                "role": "user",
                "content": "1+1=?",
            }
        ],
        "max_tokens": 200,  # 按需添加
        "temperature": 0.7, # 按需添加
        "top_k": 50,        # 按需添加
        "top_p": 0.7,       # 按需添加
        "frequency_penalty": 0 # 按需添加
    }
```

**2. 关于`max_tokens`说明**

平台提供的 LLM 模型中，

* max\_tokens 限制为 `16384`的模型：:
  * deepseek-ai/DeepSeek-R1
  * deepseek-ai/DeepSeek-R1-Distill-Qwen-32B
  * deepseek-ai/DeepSeek-R1-Distill-Qwen-14B
  * deepseek-ai/DeepSeek-R1-Distill-Qwen-7B
  * deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B
* max\_tokens 限制为 `8192` 的模型：:

  * Qwen/QwQ-32B-Preview
  * deepseek-ai/DeepSeek-R1
* max\_tokens 限制为 `4096` 的模型：

  * 除上述提到的其他 LLM 模型的

**3. 关于 `context_length` 说明**

不同的 LLM 模型，`context_length` 是有差别的，具体可以在 [模型广场](https://cloud.siliconflow.com/models) 上搜索对应的模型，
查看模型具体信息。

**4. 模型输出截断问题**

可以从以下几方面进行问题的排查：

* 通过 API 请求时候，输出截断问题排查：
  * max\_tokens 设置：max\_token 设置到合适值，输出大于 max\_token 的情况下，会被截断，deepseek R1 系列的 max\_token 最大可设置为 16384。
  * 设置流式输出请求：非流式请求时候，输出内容比较长的情况下，容易出现 504 超时。
  * 设置客户端超时时间：把客户端超时时间设置大一些，防止未输出完成，达到客户端超时时间被截断。
* 通过第三方客户端请求，输出截断问题排查：
  * CherryStdio 默认的 max\_tokens 是 4096，用户可以通过“设置”，打开“开启消息长度限制”的开关，将 max\_token 设置到合适值

**5. 错误码处理**

| 错误码     | 常见原因           | 解决方案                        |
| ------- | -------------- | --------------------------- |
| 400     | 参数格式错误         | 检查 temperature 等请求参数的取值范围   |
| 401     | API Key 没有正确设置 | 检查 API Key                  |
| 403     | 权限不够           | 最常见的原因是该模型需要实名认证，其他情况参考报错信息 |
| 429     | 请求频率超限         | 实施指数退避重试机制                  |
| 503/504 | 模型过载           | 切换备用模型节点                    |

## 5. 计费与配额管理

### 5.1 计费公式

`总费用 = (输入tokens × 输入单价) + (输出tokens × 输出单价) `

### 5.2 各系列单价示例

模型的具体价格可以进入 [模型广场](https://cloud.siliconflow.com/models) 下的模型详情页查看。

## 6. 应用案例

### 6.1 技术文档生成

```python
from openai import OpenAI
client = OpenAI(api_key="YOUR_KEY", base_url="https://api.ap.siliconflow.com/v1")
response = client.chat.completions.create(  
    model="Qwen/Qwen2.5-Coder-32B-Instruct",  
    messages=[{  
        "role": "user",  
        "content": "编写 Python 异步爬虫教程，包含代码示例和注意事项"  
    }],  
    temperature=0.7,  
    max_tokens=4096  
)  
```

### 6.2 数据分析报告

```python
from openai import OpenAI
client = OpenAI(api_key="YOUR_KEY", base_url="https://api.ap.siliconflow.com/v1")
response = client.chat.completions.create(  
    model="Qwen/QVQ-72B-Preview",  
    messages=[    
        {"role": "system", "content": "你是数据分析专家，用 Markdown 输出结果"},  
        {"role": "user", "content": "分析 2023 年新能源汽车销售数据趋势"}  
    ],  
    temperature=0.7,  
    max_tokens=4096  
)  
```

<Note> 模型能力持续更新中，建议定期访问 [模型广场](https://cloud.siliconflow.com/models) 获取最新信息。 </Note>


# 文本转语音模型
Source: https://docs.siliconflow.com/cn/userguide/capabilities/text-to-speech



## 1. 使用场景

文本转语音模型（TTS）是一种将文本信息转换为语音输出的 AI 模型。该模型将输入文本内容生成自然流畅、富有表现力的语音，适用于多种应用场景：

* 为博客文章提供音频朗读
* 生成多语言语音内容
* 支持实时流媒体音频输出

## 2. API 使用指南

* 端点：/audio/speech，具体使用可参考 [API 文档](https://docs.siliconflow.com/api-reference/audio/create-speech)
* 主要请求参数：
  * model：用于语音合成的模型，支持的 [模型列表](/capabilities/text-to-speech#3)。
  * input：待转换为音频的文本内容。
  * voice：参考音色，支持 [系统预置音色](/capabilities/text-to-speech#2-1)、[用户预置音色](/capabilities/text-to-speech#2-2)、[用户动态音色](/capabilities/text-to-speech#2-3)。
    详细参数请参考：[创建文本转语音请求](/api-reference/audio/create-speech)。
  * speed：可以控制音频速度，float 类型，默认值是 1.0，可选范围是\[0.25,4.0]；
  * gain：音频增益，单位 dB，可以控制音频声音大小，float 类型，默认值是 0.0，可选范围是\[-10,10]；
  * response\_format：控制输出格式，支持 mp3、opus、wav 和 pcm 格式。在选择不同的输出格式时，输出的采样率也会有所不同。
  * sample\_rate：可以控制输出采样率，对于不同的视频输出类型，默认值和可取值范围均不同，具体如下：
    * opus: 目前只支持 48000hz
    * wav, pcm: 支持 (8000, 16000, 24000, 32000, 44100), 默认 44100
    * mp3: 支持 (32000, 44100), 默认 44100

### 2.1 系统预置音色：

目前系统预置了如下 8 种音色：

* 男生音色：
  * 沉稳男声：alex
  * 低沉男声：benjamin
  * 磁性男声：charles
  * 欢快男声：david

* 女生音色：
  * 沉稳女声：anna
  * 激情女声：bella
  * 温柔女声：claire
  * 欢快女声：diana

在请求中 [使用系统预置音色](/capabilities/text-to-speech#5-1)。
在使用对应的系统预置音色时，需要在前面加上模型名称，比如：

`FunAudioLLM/CosyVoice2-0.5B:alex` 表示 `FunAudioLLM/CosyVoice2-0.5B` 模型下的 `alex` 音色。

{/*   `fishaudio/fish-speech-1.5:anna` 表示 `fishaudio/fish-speech-1.5` 模型下的 `anna` 音色。*/}

### 2.2 用户预置音色：

#### 2.2.1 通过 `base64` 编码格式上传用户预置音色

```python
import requests
import json

url = "https://api.ap.siliconflow.com/v1/uploads/audio/voice"
headers = {
    "Authorization": "Bearer your-api-key", # 从 https://cloud.siliconflow.com/account/ak 获取
    "Content-Type": "application/json"
}
data = {
    "model": "FunAudioLLM/CosyVoice2-0.5B", # 模型名称
    "customName": "your-voice-name", # 用户自定义的音频名称
    "audio": "data:audio/mpeg;base64,SUQzBAAAAAAAIlRTU0UAAAAOAAADTGF2ZjYxLjcuMTAwAAAAAAAAAAAAAAD/40DAAAAAAAAAAAAASW5mbwAAAA8AAAAWAAAJywAfHx8fKioqKio1NTU1Pz8/Pz9KSkpKVVVVVVVfX19fampqamp1dXV1f39/f3+KioqKlZWVlZWfn5+fn6qqqqq1tbW1tb+/v7/KysrKytXV1dXf39/f3+rq6ur19fX19f////", # 参考音频的 base64 编码
    "text": "在一无所知中，梦里的一天结束了，一个新的轮回便会开始" # 参考音频的文字内容
}

response = requests.post(url, headers=headers, data=json.dumps(data))

# 打印响应状态码和响应内容
print(response.status_code)
print(response.json())  # 如果响应是 JSON 格式
```

上述接口返回的 `uri` 字段，即为自定义音色的 ID，用户可以将其作为后续的 `voice` 参数中，进行请求。

```json
{'uri': 'speech:your-voice-name:cm04pf7az00061413w7kz5qxs:mjtkgbyuunvtybnsvbxd'}
```

在请求中 [使用用户预置音色](/capabilities/text-to-speech#5-2)。

#### 2.2.2 通过文件上传用户预置音色

```python
import requests

url = "https://api.ap.siliconflow.com/v1/uploads/audio/voice"
headers = {
    "Authorization": "Bearer your-api-key" # 从 https://cloud.siliconflow.com/account/ak 获取
}
files = {
    "file": open("/Users/senseb/Downloads/fish_audio-Alex.mp3", "rb") # 参考音频文件
}
data = {
    "model": "FunAudioLLM/CosyVoice2-0.5B", # 模型名称
    "customName": "your-voice-name", # 参考音频名称
    "text": "在一无所知中，梦里的一天结束了，一个新的轮回便会开始" # 参考音频的文字内容
}

response = requests.post(url, headers=headers, files=files, data=data)

print(response.status_code)
print(response.json())  # 打印响应内容（如果是 JSON 格式）
```

上述接口返回的 `uri` 字段，即为自定义音色的 ID，用户可以将其作为后续的 `voice` 参数中，进行请求。

```json
{'uri': 'speech:your-voice-name:cm04pf7az00061413w7kz5qxs:mjtkgbyuunvtybnsvbxd'}
```

在请求中 [使用用户预置音色](/capabilities/text-to-speech#5-2)。

### 2.3 获取用户动态音色列表

```python
import requests
url = "https://api.ap.siliconflow.com/v1/audio/voice/list"

headers = {
    "Authorization": "Bearer your-api-key" # 从 https://cloud.siliconflow.com/account/ak 获取
}
response = requests.get(url, headers=headers)

print(response.status_code)
print(response.json) # 打印响应内容（如果是 JSON 格式）
```

上述接口返回的 `uri` 字段，即为自定义音色的 ID，用户可以将其作为后续的 `voice` 参数中，进行请求。

```json
{'uri': 'speech:your-voice-name:cm04pf7az00061413w7kz5qxs:mjtkgbyuunvtybnsvbxd'}
```

在请求中[使用用户预置音色](/capabilities/text-to-speech#5-2)。

### 2.4 使用用户动态音色

<Note>注意：使用用户预置音色，需要进行实名认证。</Note>

在请求中[使用用户动态音色](/capabilities/text-to-speech#5-3)。

### 2.5 删除用户动态音色

```python
import requests

url = "https://api.ap.siliconflow.com/v1/audio/voice/deletions"
headers = {
    "Authorization": "Bearer your-api-key",
    "Content-Type": "application/json"
}
payload = {
    "uri": "speech:your-voice-name:cm02pf7az00061413w7kz5qxs:mttkgbyuunvtybnsvbxd"
}

response = requests.request("POST", url, json=payload, headers=headers)

print(response.status_code)
print(response.text) #打印响应内容
```

上述接口请求参数中的 `uri` 字段，即为自定义音色的 ID。

## 3. 支持模型列表

<Note>注意：支持的 TTS 模型可能发生调整，请在「模型广场」筛选 [“语音”标签](https://cloud.siliconflow.com/models?types=speech) 获得当前支持的模型列表。</Note>
<Note>计费方式：按照输入文本长度对应的 [UTF-8 字节](https://zh.wikipedia.org/wiki/UTF-8) 数进行计费，[在线字节计数器演示](https://mothereff.in/byte-counter)。</Note>

{/*### 3.1 fishaudio/fish-speech 系列模型
  <Note>注意：当前的 fishaudio/fish-speech 系列模型仅支持使用充值余额进行支付。在使用前，请确保账户充值余额充足。</Note>
  - fish-speech-1.5 支持语言：中文、英语、日语、德语、法语、西班牙语、韩语、阿拉伯语、俄语、荷兰语、意大利语、波兰语、葡萄牙语
  - fish-speech-1.4 支持语言：中文、英语、日语、德语、法语、西班牙语、韩语、阿拉伯语*/}

### 3.1 FunAudioLLM/CosyVoice2-0.5B 系列模型

* 跨语言语音合成：实现不同语言之间的语音合成，中文、英文、日语、韩语、中国方言（粤语，四川话，上海话，郑州话，长沙话，天津话）
* 情感控制：支持生成具有多种情感表达的语音，包括快乐、兴奋、悲伤、愤怒等。
* 细粒度控制：通过富文本或自然语言，对生成语音的情感和韵律进行细粒度控制。

## 4. 参考音频的最佳实践

提供参考音频的高质量样本可以提升语音克隆效果。

### 4.1 音频质量指南

* 仅限单一说话人
* 吐字清晰、稳定的音量、音调和情绪
* 简短的停顿（建议 0.5 秒）
* 理想情况：无背景噪音、专业录音质量、无房间回声
* 建议时间 8～10s 左右

### 4.2 文件格式

* 支持格式：mp3, wav, pcm, opus
* 推荐使用 192kbps 以上的 mp3 以避免质量损失
* 未压缩格式（例如 WAV）提供的额外优势有限

## 5. 使用示例

### 5.1 使用系统预置音色

```python
from pathlib import Path
from openai import OpenAI

speech_file_path = Path(__file__).parent / "siliconcloud-generated-speech.mp3"

client = OpenAI(
    api_key="您的 API KEY", # 从 https://cloud.siliconflow.com/account/ak 获取
    base_url="https://api.ap.siliconflow.com/v1"
)

with client.audio.speech.with_streaming_response.create(
  model="FunAudioLLM/CosyVoice2-0.5B", # 支持 fishaudio / GPT-SoVITS / CosyVoice2-0.5B 系列模型
  voice="FunAudioLLM/CosyVoice2-0.5B:alex", # 系统预置音色
  # 用户输入信息
  input="你能用高兴的情感说吗？<|endofprompt|>今天真是太开心了，马上要放假了！I'm so happy, Spring Festival is coming!",
  response_format="mp3" # 支持 mp3, wav, pcm, opus 格式
) as response:
    response.stream_to_file(speech_file_path)

```

#### 5.2 使用用户预置音色

```python
from pathlib import Path
from openai import OpenAI

speech_file_path = Path(__file__).parent / "siliconcloud-generated-speech.mp3"

client = OpenAI(
    api_key="您的 API KEY", # 从 https://cloud.siliconflow.com/account/ak 获取
    base_url="https://api.ap.siliconflow.com/v1"
)

with client.audio.speech.with_streaming_response.create(
  model="FunAudioLLM/CosyVoice2-0.5B", # 支持 fishaudio / GPT-SoVITS / CosyVoice2-0.5B 系列模型
  voice="speech:your-voice-name:cm02pf7az00061413w7kz5qxs:mttkgbyuunvtybnsvbxd", # 用户上传音色名称，参考
  # 用户输入信息
  input=" 请问你能模仿粤语的口音吗？< |endofprompt| >多保重，早休息。",
  response_format="mp3"
) as response:
    response.stream_to_file(speech_file_path)

```

#### 5.3 使用用户动态音色

```python
from pathlib import Path
from openai import OpenAI
client = OpenAI()

speech_file_path = Path(__file__).parent / "siliconcloud-generated-speech.mp3"

client = OpenAI(
    api_key="您的 API KEY", # 从 https://cloud.siliconflow.com/account/ak 获取
    base_url="https://api.ap.siliconflow.com/v1"
)

with client.audio.speech.with_streaming_response.create(
  model="FunAudioLLM/CosyVoice2-0.5B", 
  voice="", # 此处传入空值，表示使用动态音色
  # 用户输入信息
  input="[laughter] 有时候，看着小孩子们的天真行为 [laughter]，我们总会会心一笑。",
  response_format="mp3",
  extra_body={"references":[
        {
            "audio": "https://sf-maas-uat-prod.oss-cn-shanghai.aliyuncs.com/voice_template/fish_audio-Alex.mp3", # 参考音频 url。也支持 base64 格式
            "text": "在一无所知中，梦里的一天结束了，一个新的轮回便会开始", # 参考音频的文字内容
        }
    ]}
) as response:
    response.stream_to_file(speech_file_path)
```


# 视频生成模型
Source: https://docs.siliconflow.com/cn/userguide/capabilities/video



## 1. 使用场景

视频生成模型是一种利用文本或图像描述生成动态视频内容的技术，随着技术的不断发展，它的应用场景也越来越广泛。以下是一些潜在的应用领域：

1. 动态内容生成：视频生成模型可以生成动态的视觉内容，用于描述和解释信息；
2. 多模态智能交互：结合图像和文本输入，视频生成模型可用于更智能、更交互式的应用场景；
3. 替代传统视觉技术：视频生成模型可以替代或增强传统的机器视觉技术，解决更复杂的多模态问题；随着技术的进步，视频生成模型的多模态能力会与视觉语言模型融合，推动其在智能交互、自动化内容生成以及复杂场景模拟等领域的全面应用。此外，视频生成模型还能与图像生成模型（图生视频）结合，进一步拓展其应用范围，实现更加丰富和多样化的视觉内容生成。

## 2. 使用建议

在编写提示词时，请关注详细、按时间顺序描述动作和场景。包含具体的动作、外貌、镜头角度以及环境细节，所有内容都应连贯地写在一个段落中，直接从动作开始，描述应具体和精确，将自己想象为在描述镜头脚本的摄影师，提示词保持在 200 单词以内。

为了获得最佳效果，请按照以下结构构建提示词：

* 从主要动作的一句话开始
  * 示例：A woman with light skin, wearing a blue jacket and a black hat with a veil,She first looks down and to her right, then raises her head back up as she speaks.
* 添加关于动作和手势的具体细节
  * 示例：She first looks down and to her right, then raises her head back up as she speaks.
* 精确描述角色/物体的外观
  * 示例：She has brown hair styled in an updo, light brown eyebrows, and is wearing a white collared shirt under her blue jacket.
* 包括背景和环境的细节
  * 示例：The background is out of focus, but shows trees and people in period clothing.
* 指定镜头角度和移动方式
  * 示例：The camera remains stationary on her face as she speaks.
* 描述光线和颜色效果
  * 示例：The scene is captured in real-life footage, with natural lighting and true-to-life colors.
* 注意任何变化或突发事件
  * 示例：A gust of wind blows through the trees, causing the woman's veil to flutter slightly.

上述 prompt 生成的视频示例：

<video width="560" height="315" controls autoplay>
  <source src="https://mintlify.s3.us-west-1.amazonaws.com/siliconflowcom/cn/userguide/capabilities/example.mp4" type="video/mp4" />

  Your browser does not support the video tag.
</video>

## 3. 体验地址

可以点击 [Playground](https://cloud.siliconflow.com/playground/text-to-video) 进行体验

## 4. 支持模型

### 4.1 文生视频模型

目前已经支持的文生视频模型：

* Wan-AI/Wan2.1-T2V-14B

### 4.2 图生视频模型

1. 目前已经支持的图生视频模型：

* Wan-AI/Wan2.1-I2V-14B-720P

2. 图生视频的分辨率
   根据用户上传图片的宽高比自动匹配分辨率：

* 16:9 👉 1280×720
* 9:16 👉 720×1280
* 1:1 👉 960×960

为了保证最佳生成效果，建议您使用宽高比为 16:9 / 9:16 / 1:1 的图片生成视频。

<Note>注意：支持的文生视频模型可能发生调整，请在「模型广场」筛选“视频”标签，了解支持的模型列表。</Note>


# 视觉语言模型
Source: https://docs.siliconflow.com/cn/userguide/capabilities/vision



## 1. 使用场景

视觉语言模型（VLM）是一种能够同时接受视觉（图像）和语言（文本）两种模态信息输入的大语言模型。基于视觉语言模型，可以传入图像及文本信息，模型能够理解同时理解图像及上下文中的信息并跟随指令做出响应。如：

1. 视觉内容解读：要求模型对图片中包含的信息进行解读、描述，如包含的事物、文字，事物的空间关系，图像的颜色、气氛等；
2. 结合视觉内容及上下文，开展多轮会话；
3. 部分替代 OCR 等传统机器视觉模型；
4. 随着模型能力的持续提升，未来还可以用于视觉智能体、机器人等领域。

## 2. 使用方式

对于 VLM 模型，可在调用 `/chat/completions` 接口时，构造包含 `图片 url` 或 `base64 编码图片` 的 `message` 消息内容进行调用。通过 `detail` 参数控制对图像的预处理方式。

### 2.1 关于图片细节控制参数说明

SiliconCloud 提供 `low`，`high`，`auto` 三个 `detail` 参数选项。
对于目前支持的模型，`detail` 不指定或指定为 `high` 时会采用 `high`（“高分辨率”）模式，而指定为 `low` 或者 `auto` 时会采用 `low`（“低分辨率”）模式。

### 2.2 包含图像的 `message` 消息格式示例

#### 2.2.1 使用图片 url 形式

```json
{
    "role": "user",
    "content":[
        {
            "type": "image_url",
            "image_url": {
                "url": "https://sf-maas.s3.us-east-1.amazonaws.com/images/recDq23epr.png",
                "detail":"high"
            }
        },
        {
            "type": "text",
            "text": "text-prompt here"
        }
    ]
}
```

#### 2.2.2 base64 形式

```json

{
    "role": "user",
    "content":[
        {
            "type": "image_url",
            "image_url": {
                "url": f"data:image/jpeg;base64,{base64_image}",
                "detail":"low"
            }
        },
        {
            "type": "text",
            "text": "text-prompt here"
        }
    ]
}
```

```python 图片base64转换示例
from PIL import Image
import io
import base64
def convert_image_to_webp_base64(input_image_path):
    try:
        with Image.open(input_image_path) as img:
            byte_arr = io.BytesIO()
            img.save(byte_arr, format='webp')
            byte_arr = byte_arr.getvalue()
            base64_str = base64.b64encode(byte_arr).decode('utf-8')
            return base64_str
    except IOError:
        print(f"Error: Unable to open or convert the image {input_image_path}")
        return None

base64_image=convert_image_to_webp_base64(input_image_path)
```

#### 2.2.3 多图片形式，其中每个图片可以是上述两种形式之一

<Note>请注意，`DeepseekVL2` 系列模型适用于处理短上下文，建议最多传入 2 张图片。若传入超过 2 张图片，模型将自动调整图片尺寸为 384\*384，且指定的 detail 参数将无效。</Note>

```json
{
    "role": "user",
    "content":[
        {
            "type": "image_url",
            "image_url": {
                "url": "https://sf-maas.s3.us-east-1.amazonaws.com/images/recDq23epr.png",
            }
        },
        {
            "type": "image_url",
            "image_url": {
                "url": f"data:image/jpeg;base64,{base64_image}"
            }
        },
        {
            "type": "text",
            "text": "text-prompt here"
        }
    ]
}
```

## 3. 支持模型列表

目前已支持的 VLM 模型：

* Qwen 系列：
  * Qwen/Qwen2-VL-72B-Instruct
* DeepseekVL2 系列：
  * deepseek-ai/deepseek-vl2

<Note>注意：支持的 VLM 模型可能发生调整，请在「模型广场」筛选“视觉”标签，了解支持的模型列表。</Note>

## 4. 视觉输入内容计费方式

对于图片等视觉输入内容，模型会将其转化为 tokens，与文本信息一并作为模型输出的上下文信息，因此也会一并进行计费。不同模型的视觉内容转化方式不同，以下为目前支持模型的转化方式。

### 4.1 Qwen 系列

规则：

`Qwen` 最高支持像素是 `3584 * 3584= 12845056`，最低支持像素是 `56 * 56 = 3136`，会对先对每张图片长短边均放缩至 28 的倍数 `(h * 28) * (w * 28)`。如果不在最小像素和最大像素区间内，再等比缩放至该区间。

1. `detail=low` 时将所有图片 resize 成 `448 * 448` 尺寸，最终对应 `256 tokens`；
2. `detail=high` 时等比缩放，首先将长宽按照最近的 `28` 倍数向上取整，然后再等比缩放至像素区间 `(3136, 12845056)`，并保证长宽均为 `28` 整数倍。

示例：

* `224 * 448` 和 `1024 x 1024` 和 `3172 x 4096` 的图片，选择 `detail=low` 时，均消耗 `256 tokens`；
* `224 * 448` 的图片，选择 `detail=high` 时，因为 `224 * 448` 在像素区间内，且长宽均为 `28` 倍数，消耗 `(224/28) * (448/28) = 8 * 16 = 128 tokens`；
* `1024 * 1024` 的图片，选择 `detail=high` 时，将长宽按照 `28` 的倍数向上取整至 `1036 * 1036`，该数值在像素区间内，消耗 ` (1036/28) * (1036/28) = 1369 tokens`；
* `3172 * 4096` 的图片，选择 `detail=high` 时，将长宽按照 `28` 的倍数向上取整至 `3192 * 4116`，该值超过最大像素，再将长宽等比例缩小至 `3136 * 4060`，消耗 `(3136/28) * (4060/28) = 16240 tokens`。

### 4.2 DeepseekVL2 系列

规则：

`DeepseekVL2`对于每张图片，会处理`global_view`和`local_view`两部分。`global_view`将原图片统一 resize 成`384*384`像素大小，local\_view 会将每张图片划分成若干`384*384`的块大小。图片中间会根据宽度增加额外 token 来衔接。

1. `detail=low`时将所有图片 resize 成`384*384`尺寸
2. `detail=high`时会根据长宽比例，将图片 resize 成长宽均为`384(OpenAI是512)`的倍数， `(h*384) * (w * 384)`, 且`1 <= h*w <=9`。

* 放缩的长宽`h * w`按照如下规则选择：

  * `h`和`w`均为整数，在满足`1 <= h*w <=9`约束下，按照`(h, w)`组合遍历。
  * 将图片 resize 成`(h*384, w*384)`像素时，和原图片的像素比较，取新图片像素和原图片像素的最小值作为有效像素值，取原图片像素值与有效像素值之差作为无效像素值。如果有效像素值超过之前判定的有效像素值，或者当有效像素值和之前持平，但是无效像素值更小时，选择当前`(h*384, w*384)`组合

* token 消耗按照如下规则：
  * `(h*w + 1) * 196 + (w+1) * 14 + 1  token`

示例：

* `224 x 448` 和 `1024 x 1024` 和 `2048 x 4096` 的图片，选择`detail=low`时，均消耗`421token`.
* `384 x 768`的图片，选择`detail=high`时，长宽比为`1:1`, 会缩放至`384 x 768`,  此时`h=1, w=2`, 消耗
  `(1*2 +1)*196+(2+1)*14+1=631 token`.
* `1024 x 1024`的图片，选择`detail=high`时，会缩放至`1152*1152(h=w=3)`, 消耗`(3*3 + 1) * 196 + (3+1)*14+1 = 2017 token`.
* `2048 x 4096`的图片，选择`detail=high`时，长宽比例为`1:2`,  按照规则缩放至 `768*1536(h=2,w=4)`, 消耗 `(2*4 + 1) * 196 + (4+1)*14+1 = 1835 token`.

## 5. 使用示例

### 5.1. 示例 1 图片理解

```python
import json  
from openai import OpenAI

client = OpenAI(
    api_key="您的 API KEY", # 从 https://cloud.siliconflow.com/account/ak获取
    base_url="https://api.ap.siliconflow.com/v1"
)

response = client.chat.completions.create(
        model="Qwen/Qwen2-VL-72B-Instruct",
        messages=[
        {
            "role": "user",
            "content": [
                {
                    "type": "image_url",
                    "image_url": {
                        "url": "https://sf-maas.s3.us-east-1.amazonaws.com/images/recu6XreBFQ0st.png"
                    }
                },
                {
                    "type": "text",
                    "text": "Describe the image."
                }
            ]
        }],
        stream=True
)

for chunk in response:
    chunk_message = chunk.choices[0].delta.content
    print(chunk_message, end='', flush=True)
```

### 5.2. 示例 2 多图理解

```python
import json  
from openai import OpenAI

client = OpenAI(
    api_key="您的 API KEY", # 从 https://cloud.siliconflow.com/account/ak 获取
    base_url="https://api.siliconflow.c/v1"
)

response = client.chat.completions.create(
        model="Qwen/Qwen2-VL-72B-Instruct",
        messages=[
        {
            "role": "user",
            "content": [
                {
                    "type": "image_url",
                    "image_url": {
                        "url": "https://sf-maas.s3.us-east-1.amazonaws.com/images/recu6XreBFQ0st.png"
                    }
                },
                {
                    "type": "image_url",
                    "image_url": {
                        "url": "https://sf-maas.s3.us-east-1.amazonaws.com/images/recu6Xrf2Cd0cn.png"
                    }
                },
                {
                    "type": "text",
                    "text": "Identify the similarities between these images."
                }
            ]
        }],
        stream=True
)

for chunk in response:
    chunk_message = chunk.choices[0].delta.content
    print(chunk_message, end='', flush=True)

```


# FIM 补全
Source: https://docs.siliconflow.com/cn/userguide/guides/fim



## 1. 使用场景

FIM (Fill In the Middle) 补全中，用户提供希望输入的前后内容，模型来补全中间的内容，典型用于代码补全、文本中间内容补全等场景中。

## 2. 使用方式

### 2.1 在 chat/completions 接口中使用

```json
{ 
    "model": "model info",
    "messages": "prompt message",
    "params": "params",
    "extra_body": {"prefix":"前缀内容", "suffix":"后缀内容"}
}
```

### 2.2 在 completions 接口中使用

```json
{
    "model": "model info",
    "prompt": "前缀内容",
    "suffix": "后缀内容"
}
```

## 3. 支持模型列表

* Deepseek 系列：
  * deepseek-ai/DeepSeek-V3

* Qwen 系列：
  * Qwen/Qwen2.5-Coder-32B-Instruct

<Note>注意：支持的模型列表可能会发生变化，请查阅 [本文档](/features/fim) 了解最新支持的模型列表。</Note>

{/* <Note>模型的最大补全长度和[max_tokens 参数](/api-reference/chat-completions/chat-completions)保持一致。</Note> */}

## 4. 使用示例

### 4.1 基于 OpenAI 的 chat.completions 接口使用 FIM 补全：

```python
client = OpenAI(
    api_key="您的 APIKEY", # 从 https://cloud.siliconflow.com/account/ak 获取
    base_url="https://api.ap.siliconflow.com/v1"
)
 
messages = [
    {"role": "user", "content": "Please write quick sort code"},
]

response = client.chat.completions.create(
    model="deepseek-ai/DeepSeek-V2.5",
    messages=messages,
    extra_body={
            "prefix": f"""
def quick_sort(arr):
    # 基本情况，如果数组长度小于等于 1，则返回数组
    if len(arr) <= 1:
        return arr
    else:
""",
            "suffix": f"""
# 测试 quick_sort 函数
arr = [3, 6, 8, 10, 1, 2, 1]
sorted_arr = quick_sort(arr)
print("Sorted array:", sorted_arr)
"""
    },
    stream=True,
    max_tokens=4096
)

for chunk in response:
    print(chunk.choices[0].delta.content, end='')
```

### 4.2 基于 OpenAI 的 completions 接口使用 FIM 补全：

```python
client = OpenAI(
    api_key="您的 APIKEY", # 从 https://cloud.siliconflow.com/account/ak 获取
    base_url="https://api.ap.siliconflow.com/v1"
)

response = client.completions.create(
    model="deepseek-ai/DeepSeek-V2.5",
    prompt=f"""
def quick_sort(arr):
    # 基本情况，如果数组长度小于等于 1，则返回数组
    if len(arr) <= 1:
        return arr
    else:
""",
    suffix=f"""
# 测试 quick_sort 函数
arr = [3, 6, 8, 10, 1, 2, 1]
sorted_arr = quick_sort(arr)
print("Sorted array:", sorted_arr)
""",
    stream=True,
    max_tokens=4096
)

for chunk in response:
    print(chunk.choices[0].text, end='')
```


# Function Calling
Source: https://docs.siliconflow.com/cn/userguide/guides/function-calling



## 1. 使用场景

Function Calling 功能让模型能够调用外部工具，来增强自身能力。
该能力可以通过外部工具，通过大模型作为大脑调用外部工具（如搜索外部知识、查阅行程、或者某些特定领域工具），有效解决模型的幻觉、知识时效性等问题。

## 2. 使用方式

### 2.1 通过 REST API 添加 tools 请求参数

在请求体中添加

```shell
"tools": [
    {
        'type': 'function',
        'function': {
            'name': '对应到实际执行的函数名称',
            'description': '此处是函数相关描述',
            'parameters': {
                '_comments': '此处是函数参数相关描述'
            },
        }
    },
    {
        '_comments': '其他函数相关说明'
    }
]
```

比如完整的 payload 信息：

```shell
payload = {
    "model": "deepseek-ai/DeepSeek-V2.5",
    "messages": [
        {
            "role": "user",
            "content": "中国大模型行业2025年将会迎来哪些机遇和挑战"
        }
    ],
    "tools": [
    {
        'type': 'function',
        'function': {
            'name': '对应到实际执行的函数名称',
            'description': '此处是函数相关描述',
            'parameters': {
                '_comments': '此处是函数参数相关描述'
            },
        }
    },
    {
        '_comments': '其他函数相关说明'
    }
    ]
    '_comments': '其他函数列表'
}
```

### 2.2 通过 OpenAI 库请求

该功能和 OpenAI 兼容，在使用 OpenAI 的库时，对应的请求参数中添加`tools=[对应的 tools]`
比如：

```python
response = client.chat.completions.create(
    model="deepseek-ai/DeepSeek-V2.5",
    messages = messages,
    tools=[
        {
            'type': 'function',
            'function': {
                'name': '对应到实际执行的函数名称',
                'description': '此处是函数相关描述',
                'parameters': {
                    // 此处是函数参数相关描述
                },
            }
        },
        {
            // 其他函数相关说明
        }
    ]
    // chat.completions 其他参数
)
```

## 3. 支持模型列表

目前支持的模型列表有：

* GLM 系列：
  * THUDM/glm-4-9b-chat

* Deepseek 系列：
  * deepseek-ai/DeepSeek-R1
  * deepseek-ai/DeepSeek-V3
  * deepseek-ai/DeepSeek-R1-Distill-Qwen-32B
  * deepseek-ai/DeepSeek-R1-Distill-Qwen-14B
  * deepseek-ai/DeepSeek-R1-Distill-Qwen-7B
  * deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B

* Qwen 系列：
  * Qwen/Qwen2.5-72B-Instruct
  * Qwen/Qwen2.5-32B-Instruct
  * Qwen/Qwen2.5-14B-Instruct
  * Qwen/Qwen2.5-7B-Instruct

<Note>注意：支持的模型列表在不断调整中，请查阅 [本文档](/features/function_calling) 了解最新支持的模型列表。</Note>

## 4. 使用示例

### 4.1. 示例 1：通过 function calling 来扩展大语言模型的数值计算能力

本代码输入 4 个函数，分别是数值的加、减、比较大小、字符串中重复字母计数四个函数
来演示通过 function calling 来解决大语言模型在 tokens 预测不擅长的领域的执行问题。

```python

from openai import OpenAI

client = OpenAI(
    api_key="您的 APIKEY", # 从 https://cloud.siliconflow.com/account/ak 获取
    base_url="https://api.ap.siliconflow.com/v1"
)

def add(a: float, b: float):
    return a + b

def mul(a: float, b: float):
    return a * b

def compare(a: float, b: float):
    if a > b:
        return f'{a} is greater than {b}'
    elif a < b:
        return f'{b} is greater than {a}'
    else:
        return f'{a} is equal to {b}'

def count_letter_in_string(a: str, b: str):
    string = a.lower()
    letter = b.lower()
    
    count = string.count(letter)
    return(f"The letter '{letter}' appears {count} times in the string.")


tools = [
{
    'type': 'function',
    'function': {
        'name': 'add',
        'description': 'Compute the sum of two numbers',
        'parameters': {
            'type': 'object',
            'properties': {
                'a': {
                    'type': 'int',
                    'description': 'A number',
                },
                'b': {
                    'type': 'int',
                    'description': 'A number',
                },
            },
            'required': ['a', 'b'],
        },
    }
}, 
{
    'type': 'function',
    'function': {
        'name': 'mul',
        'description': 'Calculate the product of two numbers',
        'parameters': {
            'type': 'object',
            'properties': {
                'a': {
                    'type': 'int',
                    'description': 'A number',
                },
                'b': {
                    'type': 'int',
                    'description': 'A number',
                },
            },
            'required': ['a', 'b'],
        },
    }
},
{
    'type': 'function',
    'function': {
        'name': 'count_letter_in_string',
        'description': 'Count letter number in a string',
        'parameters': {
            'type': 'object',
            'properties': {
                'a': {
                    'type': 'str',
                    'description': 'source string',
                },
                'b': {
                    'type': 'str',
                    'description': 'letter',
                },
            },
            'required': ['a', 'b'],
        },
    }
},
{
    'type': 'function',
    'function': {
        'name': 'compare',
        'description': 'Compare two number, which one is bigger',
        'parameters': {
            'type': 'object',
            'properties': {
                'a': {
                    'type': 'float',
                    'description': 'A number',
                },
                'b': {
                    'type': 'float',
                    'description': 'A number',
                },
            },
            'required': ['a', 'b'],
        },
    }
}
]

def function_call_playground(prompt):
    messages = [{'role': 'user', 'content': prompt}]
    response = client.chat.completions.create(
        model="deepseek-ai/DeepSeek-V2.5",
        messages = messages,
        temperature=0.01,
        top_p=0.95,
        stream=False,
        tools=tools)

    # print(response)
    func1_name = response.choices[0].message.tool_calls[0].function.name
    func1_args = response.choices[0].message.tool_calls[0].function.arguments
    func1_out = eval(f'{func1_name}(**{func1_args})')
    # print(func1_out)

    messages.append(response.choices[0].message)
    messages.append({
        'role': 'tool',
        'content': f'{func1_out}',
        'tool_call_id': response.choices[0].message.tool_calls[0].id
    })
    # print(messages)
    response = client.chat.completions.create(
        model="deepseek-ai/DeepSeek-V2.5",
        messages=messages,
        temperature=0.01,
        top_p=0.95,
        stream=False,
        tools=tools)
    return response.choices[0].message.content
  
prompts = [
    "用中文回答：strawberry 中有多少个 r?", 
    "用中文回答：9.11 和 9.9，哪个小？"
]

for prompt in prompts:
    print(function_call_playground(prompt))
```

模型将输出：

```shell
strawberry 中有 3 个 r。
9.11 比 9.9 小。
```

### 4.2. 示例 2：通过 function calling 来扩展大语言模型对外部环境的理解

本代码输入 1 个函数，通过外部 API 来查询外部信息

```python
import requests
from openai import OpenAI

client = OpenAI(
    api_key="您的 APIKEY", # 从 https://cloud.siliconflow.com/account/ak 获取
    base_url="https://api.ap.siliconflow.com/v1"
)

# 使用 WeatherAPI 的天气查询函数
def get_weather(city: str):
    # 使用 WeatherAPI 的 API 来获取天气信息
    api_key = "您的 WeatherAPI APIKEY"  # 替换为你自己的 WeatherAPI APIKEY
    base_url = "http://api.weatherapi.com/v1/current.json"
    params = {
        'key': api_key,
        'q': city,
        'aqi': 'no'  # 不需要空气质量数据
    }
    
    # 调用天气 API
    response = requests.get(base_url, params=params)
    
    if response.status_code == 200:
        data = response.json()
        weather = data['current']['condition']['text']
        temperature = data['current']['temp_c']
        return f"The weather in {city} is {weather} with a temperature of {temperature}°C."
    else:
        return f"Could not retrieve weather information for {city}."

# 定义 OpenAI 的 function calling tools
tools = [
    {
        'type': 'function',
        'function': {
            'name': 'get_weather',
            'description': 'Get the current weather for a given city.',
            'parameters': {
                'type': 'object',
                'properties': {
                    'city': {
                        'type': 'string',
                        'description': 'The name of the city to query weather for.',
                    },
                },
                'required': ['city'],
            },
        }
    }
]

# 发送请求并处理 function calling
def function_call_playground(prompt):
    messages = [{'role': 'user', 'content': prompt}]
    
    # 发送请求到 OpenAI API
    response = client.chat.completions.create(
        model="deepseek-ai/DeepSeek-V2.5",
        messages=messages,
        temperature=0.01,
        top_p=0.95,
        stream=False,
        tools=tools
    )

    # 处理 API 返回的工具调用请求
    func1_name = response.choices[0].message.tool_calls[0].function.name
    func1_args = response.choices[0].message.tool_calls[0].function.arguments
    func1_out = eval(f'{func1_name}(**{func1_args})')

    # 将结果添加到对话中并返回
    messages.append(response.choices[0].message)
    messages.append({
        'role': 'tool',
        'content': f'{func1_out}',
        'tool_call_id': response.choices[0].message.tool_calls[0].id
    })
    
    # 返回模型响应
    response = client.chat.completions.create(
        model="deepseek-ai/DeepSeek-V2.5",
        messages=messages,
        temperature=0.01,
        top_p=0.95,
        stream=False,
        tools=tools
    )
    
    return response.choices[0].message.content

# 示例使用
prompt = "how is the weather today in beijing?"
print(function_call_playground(prompt))
```

模型将输出：

```shell
The weather in Beijing today is sunny with a temperature of 21.4°C.
```


# JSON 模式
Source: https://docs.siliconflow.com/cn/userguide/guides/json-mode



## 1. 使用场景

目前，SiliconFlow 的大模型 API 平台 SiliconCloud 默认生成**非结构化文本**，但在某些应用场景中，您可能希望模型以**结构化**的形式输出内容，但用提示词的方式直接告诉大模型却无法获得正确的结构化输出。

作为一种标准化、轻量级的数据交换格式，JSON 模式是支持大模型 API 进行结构化输出的重要功能。当您调用大模型的 API 进行请求时，模型返回的结果以 JSON 格式呈现，易于人类阅读和编写，同时也易于机器解析和生成。

现在，SiliconCloud 平台上除了 DeepSeek 的 R1 系列和 V3 模型外，其他主要语言模型均已支持 JSON 模式，能让模型输出 JSON 格式的字符串，以确保模型以预期的结构输出，便于后续对输出内容进行逻辑解析。

比如，您现在可以通过 SiliconCloud API 对以下案例尝试结构化输出：

* 从公司相关报道中构建新闻数据库，包括新闻标题、链接等。
* 从商品购买评价中提取出情感分析结构，包括情感极性（正面、负面、中性）、情感强度、情感关键词等。
* 从商品购买历史中提取出产品列表，包括产品信息、推荐理由、价格、促销信息等。

## 2. 使用方式

在请求中添加

```json
response_format={"type": "json_object"}
```

## 3. 支持模型列表

目前线上，平台提供的大语言类模型都支持上述参数。

<Note>注意：支持的模型情况可能会发生变化，请查阅本文档了解最新支持的模型列表。</Note>
<Note>你的应用必须检测并处理可能导致模型输出不完整 JSON 对象的边缘案例。</Note>
<Note>请合理设置 max\_tokens，防止 JSON 字符串被中断。</Note>

## 4. 使用示例

下面是在 openai 中使用的例子：

```python
import json  
from openai import OpenAI

client = OpenAI(
    api_key="您的 APIKEY", # 从 https://cloud.siliconflow.com/account/ak 获取
    base_url="https://api.ap.siliconflow.com/v1"
)

response = client.chat.completions.create(
        model="deepseek-ai/DeepSeek-V2.5",
        messages=[
            {"role": "system", "content": "You are a helpful assistant designed to output JSON."},
            {"role": "user", "content": "? 2020 年世界奥运会乒乓球男子和女子单打冠军分别是谁？"
             "Please respond in the format {\"男子冠军\": ..., \"女子冠军\": ...}"}
        ],
        response_format={"type": "json_object"}
    )

print(response.choices[0].message.content)
```

模型将输出：

```json
{"男子冠军": "马龙", "女子冠军": "陈梦"}
```


# 前缀续写
Source: https://docs.siliconflow.com/cn/userguide/guides/prefix



## 1. 使用场景

前缀续写中，用户提供希望输出的前缀信息，来让模型基于用户提供的前缀信息来补全其余的内容。
基于上述能力，模型能有更好的指令遵循能力，满足用户一些特定场景的指定格式的问题。

## 2. 使用方式

在请求中添加

```json
extra_body={"prefix":"希望的前缀内容"}
```

## 3. 支持模型列表

目前 [大语言类模型](https://cloud.siliconflow.com/models?types=chat) 支持上述参数。

<Note>注意：支持的模型情况可能会发生变化，请查阅本文档了解最新支持的模型列表。</Note>

## 4. 使用示例

下面是基于 OpenAI 库使用前缀续写的例子：

````python
client = OpenAI(
    api_key="您的 APIKEY", # 从 https://cloud.siliconflow.com/account/ak 获取
    base_url="https://api.ap.siliconflow.com/v1"
)
 
messages = [
    {"role": "user", "content": "Please write quick sort code"},
]

response = client.chat.completions.create(
    model="deepseek-ai/DeepSeek-V2.5",
    messages=messages,
    extra_body={"prefix":"```python\n"}
)

print(response.choices[0].message.content)
````


# 产品简介
Source: https://docs.siliconflow.com/cn/userguide/introduction



## 1. 产品介绍

* 作为集合顶尖大模型的一站式云服务平台，[SiliconCloud](https://siliconflow.com/zh-cn/siliconcloud) 致力于为开发者提供更快、更全面、体验更丝滑的模型 API，助力开发者和企业聚焦产品创新，无须担心产品大规模推广所带来的高昂算力成本。

## 2. 产品功能

1. 提供开箱即用的大模型 API，按量收费，助力应用开发轻松实现。
   * 已上架包括 DeepSeek-R1、DeepSeek-V3、GLM-4-9B-Chat、QwQ32B、Llama 3.3 70B Instruct、Qwen2.5 72B Instruct、Qwen2.5 Coder 32B Instruct、FLUX.1-dev、FLUX.1-schnell、CosyVoice2-0.5B 在内的多种开源大语言模型、图片生成模型、代码生成模型、向量与重排序模型以及多模态大模型，覆盖语言、语音、图片、视频等多场景。
2. 提供高效能大模型推理加速服务，提升 GenAI 应用的用户体验。

## 3. 产品特性

1. **高速推理**
   * 自研高效算子和优化框架，推理加速引擎全球领先。
   * 极致提升吞吐能力，全面支持高吞吐场景的业务需求。
   * 显著优化计算延迟，为低延迟场景提供卓越性能保障。
2. **高扩展性**
   * 动态扩容支持弹性业务模型，无缝适配多种复杂场景。
   * 一键部署自定义模型，轻松应对规模化挑战。
   * 灵活架构设计，满足多样化任务需求，支持混合云部署。
3. **高性价比**
   * 端到端极致优化，推理和部署成本显著降低。
   * 提供灵活按需付费模式，减少资源浪费，精准控制预算。
   * 支持异构 GPU 部署，基于企业已有投资，节省企业投入。
4. **高稳定性**
   * 经过开发者验证，保证高可靠稳定运行。
   * 提供完善的监控和容错机制，保障服务能力。
   * 提供专业技术支持，满足企业级场景需求，确保服务高可用性。
5. **高智能**
   * 提供多种先进模型服务，包括大语言模型、音视频等多模态模型。
   * 智能扩展功能，灵活适配业务规模，满足多种服务需求。
   * 智能成本分析，为业务优化提供支持，助力成本管控与效益提升。
6. **高安全性**
   * 支持 BYOC 部署，全面保护数据隐私与业务安全。
   * 计算隔离/网络隔离/存储隔离，保障数据安全。
   * 符合行业标准与合规要求，全面满足企业级用户的安全需求。


# 快速上手
Source: https://docs.siliconflow.com/cn/userguide/quickstart



## 1. 登录平台

创建一个 [SiliconCloud](https://cloud.siliconflow.com/) 帐户。

## 2. 查看模型列表和模型详情

通过 [模型广场](https://cloud.siliconflow.com/models) 查看当前可用的模型详情、模型价格、用户可用的最高限速等信息，并可以通过模型详情页的“在线体验”测试模型。

## 3. 在 playground 体验 GenAI 能力

进入 [“体验中心 ( playground )”](https://cloud.siliconflow.com/) 页面，左侧栏可选择语言模型、文生图模型和图生图模型，选择相应模型即可开始实时体验。输入相关参数及 prompt，点击“运行”按钮，即可看到模型生成的结果。

## 4. 使用 SiliconCloud API 调用 GenAI 能力

### 4.1 创建 API key

进入 [API 密钥](https://cloud.siliconflow.com/account/ak) 页面，点击“新建 API 密钥”，创建您的 API key。

### 4.2 通过 REST 接口进行服务调用

您可以直接在平台的 [“文档链接”](https://docs.siliconflow.com/cn/api-reference/chat-completions/chat-completions) 中使用您的 API key 进行在线调用，此处可以生成对应语言的代码。

### 4.3 通过 OpenAI 接口调用

当前大语言模型部分支持以 openai 库进行调用，
安装 Python3.7.1 或更高版本并设置虚拟环境后，即可安装 OpenAI Python 库。从终端/命令行运行：

```shell
pip install --upgrade openai
```

完成此操作后，running 将显示您在当前环境中安装的 Python 库，确认 OpenAI Python 库已成功安装。
之后可以直接通过 OpenAI 的相关接口进行调用，目前平台支持 OpenAI 相关的大多数参数。

```python
from openai import OpenAI

client = OpenAI(api_key="YOUR_API_KEY", base_url="https://api.ap.siliconflow.com/v1")
response = client.chat.completions.create(
    model='deepseek-ai/DeepSeek-R1',
    messages=[
        {'role': 'user', 
        'content': "tell me a story"}
    ],
    stream=True
)

for chunk in response:
    if not chunk.choices:
        continue
    if chunk.choices[0].delta.content:
        print(chunk.choices[0].delta.content, end="", flush=True)
    if chunk.choices[0].delta.reasoning_content:
        print(chunk.choices[0].delta.reasoning_content, end="", flush=True)
```


# 结合 Cursor 使用
Source: https://docs.siliconflow.com/cn/userguide/use-docs-with-cursor



SiliconCloud 文档站支持 [llms.txt 协议](https://llmstxt.org/)，既可供用户直接查阅，也可无缝对接各类支持该协议的工具进行使用。<br />
考虑到部分用户可能对  [llms.txt 协议](https://llmstxt.org/) 不够熟悉，下面将简要介绍使用流程及相关概述。

## 1. 在 Cursor 中使用本文档

1. 打开 `Cursor` 工程后，通过 `commond + L` 打开 chat；
2. 在文本框中输入 `@` ，在菜单中选择 `Docs`，点击 `Add new doc`，输入要使用的文档地址；
3. 添加成功后，可以在 `chat` 中输入你的问题，获得相应结果。

## 2. 关于 llmx.txt 的相关介绍 

### 2.1 协议背景

llms.txt 是一种新兴的 Web 标准，旨在帮助大型语言模型（LLMs）更有效地访问和理解网站内容。通过在网站根目录下创建 llms.txt 文件，网站所有者可以为 AI 系统提供清晰的导航和指引，从而提升信息检索的效率。

### 2.2 文件结构：

llms.txt 文件采用 Markdown 格式，通常包含以下部分：

1. 标题：网站名称或项目名称。
2. 描述（可选）：对网站或项目的简要介绍。
3. 详细信息（可选）：提供更多背景信息或链接到其他文档。
4. 章节：列出网站的重要部分，每个部分包含链接和可选的详细说明。

示例如下（参考：[https://docs.siliconflow.com/llms.txt](https://docs.siliconflow.com/llms.txt) 和 [https://docs.siliconflow.com/llms-full.txt](https://docs.siliconflow.com/llms-full.txt) 文件)

```markdown
# SiliconFlow

## Docs
- [创建语音转文本请求](https://docs.siliconflow.com/api-reference/audio/create-audio-transcriptions): Creates an audio transcription.
- [创建文本转语音请求](https://docs.siliconflow.com/api-reference/audio/create-speech): 从输入文本生成音频。根据输入的文本生成音频。接口生成的数据为音频的二进制数据，需要使用者自行处理。参考：https://docs.siliconflow.com/capabilities/text-to-speech#5
- [删除参考音频](https://docs.siliconflow.com/api-reference/audio/delete-voice): 删除用户预置音色
- [上传参考音频](https://docs.siliconflow.com/api-reference/audio/upload-voice): 上传用户预置音色，支持以 base64 编码或者文件形式上传，参考 https://docs.siliconflow.com/capabilities/text-to-speech#2-2)
- [参考音频列表获取](https://docs.siliconflow.com/api-reference/audio/voice-list): 获取用户预置音色列表
...
```

### 2.3 文件作用

#### 2.3.1 /llms.txt:

* 大规模人工智能友好导航：该文件提供了整个文档导航的简化视图，使 Cursor 或 ChatGPT 等 LLM 可以更轻松地索引您的内容。
* 将其视为人工智能的搜索引擎优化--用户现在可以直接通过通用的 LLM 找到特定产品的信息。

#### 2.3.2 /llms-full.txt:

* 文件会将所有文档文本编译成一个标记符文件，便于人工智能工具基于该文件将信息直接载入其上下文窗口。
* 可以将文档输入到 Cursor 等人工智能编码助手中，让它们根据您产品的具体细节提供上下文感知建议。

### 2.4 与现有标准的区别：

虽然 llms.txt 与 robots.txt 和 sitemap.xml 等现有标准在功能上有所重叠，但它们的目的和作用不同：

* robots.txt：用于指示搜索引擎爬虫哪些页面可以或不可以抓取，主要关注访问权限控制。
* sitemap.xml：提供网站的结构地图，帮助搜索引擎了解网站的页面布局，主要用于索引目的。
* llms.txt：为大型语言模型提供结构化的内容概述，帮助 AI 系统更好地理解和处理网站信息，提升与 AI 交互的效果。

## 3. 在其他工具中使用

其他平台如果支持 [llms.txt 协议](https://llmstxt.org/)，也可以直接使用。比如，向 ChatGPT 提问：

```markdown
https://docs.siliconflow.com/llms-full.txt  What does SiliconFlow focus on?
```

## 4. 扩展阅读

1. The /llms.txt file, [https://llmstxt.org/](https://llmstxt.org/)
2. @Docs, [https://docs.cursor.com/context/@-symbols/@-docs](https://docs.cursor.com/context/@-symbols/@-docs)


