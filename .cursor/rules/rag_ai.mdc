---
description: 
globs: 
alwaysApply: false
---
# RAG and AI Integration Rules

## LLM Integration

- Use Langchain as the primary framework for RAG implementation
- Implement proper error handling for API failures
- Consider fallback mechanisms for LLM API outages
- Cache API responses when appropriate to reduce costs
- Log LLM inputs and outputs for debugging and improvement

## Prompt Engineering

- Store prompt templates separately in the `prompts/` directory
- Use a templating system for dynamic prompt generation
- Implement version control for prompts
- Document the purpose and expected output format for each prompt
- Include examples and edge cases in prompt documentation
- Consider few-shot learning approaches for complex tasks

## Vector Database Integration

- Properly abstract vector store operations behind interfaces
- Support multiple vector stores (Chroma, FAISS) through a common interface
- Use appropriate vector dimensions based on the embedding model
- Consider chunking strategies based on content type
- Implement proper indexing for efficient retrieval
- Add metadata to vector entries for filtering capabilities

## Document Processing

- Implement consistent document processing pipelines
- Use appropriate chunking strategies:
  - Text: semantic paragraphs or fixed token windows with overlap
  - Structured data: maintain relationship between fields
- Normalize text before embedding (lowercase, remove extra whitespace, etc.)
- Consider content-aware chunking for better retrieval
- Implement document source tracking

## Embedding Models

- Choose embedding models appropriate for the domain
- Consider dimensionality, performance, and cost tradeoffs
- Implement caching for embeddings to improve performance
- Normalize embeddings when required by the vector store
- Monitor embedding quality and relevance

## Retrieval Strategies

- Implement hybrid retrieval when appropriate (keyword + semantic)
- Use relevance scoring to filter results
- Consider diversity in results for better coverage
- Experiment with different similarity metrics (cosine, dot product, etc.)
- Implement re-ranking for improved relevance

## Data Sources Integration

- Abstract data source specifics behind clean interfaces
- Handle rate limiting and API quotas gracefully
- Implement proper error handling for each data source
- Consider caching strategies to reduce API calls
- Document authentication requirements for each source

## Project Structure for RAG Components

```
app/
├── rag/
│   ├── __init__.py
│   ├── orchestrator.py          # Main RAG workflow
│   ├── document_loader.py       # Interface for document loading
│   ├── loaders/                 # Specific source loaders
│   │   ├── __init__.py
│   │   ├── xiaohongshu_loader.py
│   │   └── google_maps_loader.py
│   ├── retriever.py             # Vector retrieval logic
│   ├── prompt_engine.py         # Prompt management
│   └── llm_client.py            # LLM API client
├── vector_store/                # Vector database integration
│   ├── __init__.py
│   ├── vector_store_service.py  # Abstract interface
│   └── implementations/
│       ├── __init__.py
│       ├── chroma_service.py
│       └── faiss_service.py
└── prompts/                     # Prompt templates
    └── travel_plan_prompt.txt
```

## Performance Considerations

- Monitor token usage and API costs
- Implement caching at appropriate levels
- Consider batching for embedding operations
- Optimize chunk size for retrieval quality vs. cost
- Implement appropriate timeouts for external API calls

## Testing RAG Systems

- Create test fixtures with expected retrieval results
- Test retrieval quality with known queries
- Test prompt template rendering
- Mock LLM APIs in unit tests
- Implement evaluation metrics for retrieval quality
- Consider human evaluation for complex outputs

## Security and Ethics

- Never embed sensitive or personal information
- Implement proper access controls for the API
- Consider bias in training data and generated content
- Implement content filtering for harmful or inappropriate content
- Be transparent about AI-generated content
- Follow responsible AI practices

## Documentation

- Document embedding model specifications and parameters
- Document retrieval strategies and their justifications
- Maintain examples of successful and failed retrievals
- Document rate limits and cost considerations
- Create user guides for prompt engineering

